{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZLQid0ZDDNj",
        "outputId": "0e94232e-71c0-4c05-942c-cf5f6a5223f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## install segmentation-models\n",
        "this package containes segmentation models predefined with pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2kVf3xTEk3M",
        "outputId": "4e32e79d-6b4e-47b6-f76f-a512588b3eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation-models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.5.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.7.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation-models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d89IWx5eDo15"
      },
      "source": [
        "### Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW8U2we7VESL",
        "outputId": "72ed41bf-9d80-4603-f605-f1ce788be515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.2\n",
            "  Downloading tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 4.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.47.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.14.1)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
            "\u001b[K     |████████████████████████████████| 454 kB 67.6 MB/s \n",
            "\u001b[?25hCollecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.3.0,>=2.2.0\n",
            "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 63.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.37.1)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.6.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.3.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, scipy, h5py, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.4.1 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.14 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 scipy-1.4.1 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.3.1\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.21.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed keras-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segmentation-models in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.8)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip3 install tensorflow==2.2\n",
        "!pip3 install keras==2.3.1\n",
        "!pip3 install -U segmentation-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uCRVXsNVVGUz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import segmentation_models as sm\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y-QZbAVjVjKC"
      },
      "outputs": [],
      "source": [
        "SIZE_Y = 256\n",
        "SIZE_X = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n9cwnmcWstA"
      },
      "source": [
        "# Load Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LaX9t8hDVk8T"
      },
      "outputs": [],
      "source": [
        "img_dir = os.listdir(\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/train/a/\")\n",
        "train_images = []\n",
        "for index,img_id in enumerate(img_dir):\n",
        "  img_path = f\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/train/a/{img_id}\"\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
        "  img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  train_images.append(img)\n",
        "  if index == 149:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "l0JEqXl-V-ID"
      },
      "outputs": [],
      "source": [
        "train_images = np.array(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAVgWRsVWY7K",
        "outputId": "d389241b-66d0-478c-f875-400fe87b72e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(92, 256, 256, 3)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UyyWgRSFWF7i"
      },
      "outputs": [],
      "source": [
        "img_dir = os.listdir(\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/train/b/\")\n",
        "train_masks = []\n",
        "for index,img_id in enumerate(img_dir):\n",
        "  img_path = f\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/train/b/{img_id}\"\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
        "  img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  train_masks.append(img)\n",
        "  if index == 149:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gMDkJwhpWWhy"
      },
      "outputs": [],
      "source": [
        "train_masks = np.array(train_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFO4dEIRWnRi",
        "outputId": "eb1301cc-0652-4f8d-8d3b-c334e40a7e24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(92, 256, 256, 3)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_masks.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e-YodNpWuqK"
      },
      "source": [
        "# Load Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CGcXEsc9WpzS"
      },
      "outputs": [],
      "source": [
        "img_dir = os.listdir(\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/test/a/\")\n",
        "test_images = []\n",
        "for index,img_id in enumerate(img_dir):\n",
        "  img_path = f\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/test/a/{img_id}\"\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
        "  img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  test_images.append(img)\n",
        "  if index == 149:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0hM3BpOFW2dL"
      },
      "outputs": [],
      "source": [
        "test_images = np.array(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYbSQ-tqXBLy",
        "outputId": "92628152-86dd-4914-995a-10fa03cb2498"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23, 256, 256, 3)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "I1CiskdlXFFC"
      },
      "outputs": [],
      "source": [
        "img_dir = os.listdir(\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/test/b/\")\n",
        "test_masks = []\n",
        "for index,img_id in enumerate(img_dir):\n",
        "  img_path = f\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/test/b/{img_id}\"\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
        "  img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  test_masks.append(img)\n",
        "  if index == 149:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hH_CC2D1XOIj"
      },
      "outputs": [],
      "source": [
        "test_masks = np.array(test_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBTEZi-UXTZa",
        "outputId": "aa0b8181-439a-4914-b499-08bee1054cb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23, 256, 256, 3)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_masks.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### preprocess input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "nQ4PSXmGXVti"
      },
      "outputs": [],
      "source": [
        "train_images = preprocess_input(train_images)\n",
        "test_images = preprocess_input(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "N6fQY0hbXiba"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lAc_1Ag7Xk6a"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "IMG_CHANNELS = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define LinkNet\n",
        "### 20,325,427 Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0z6-PPJrwH-",
        "outputId": "6ec1fe44-386f-4ca4-a0f1-eacb902b1465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 8, 8, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_block1_conv (Conv2D)     (None, 8, 8, 512)    2359296     block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_block1_bn (BatchNormaliz (None, 8, 8, 512)    2048        center_block1_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_block1_relu (Activation) (None, 8, 8, 512)    0           center_block1_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "center_block2_conv (Conv2D)     (None, 8, 8, 512)    2359296     center_block1_relu[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_block2_bn (BatchNormaliz (None, 8, 8, 512)    2048        center_block2_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_block2_relu (Activation) (None, 8, 8, 512)    0           center_block2_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_conv (Conv2D)   (None, 8, 8, 128)    65536       center_block2_relu[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_bn (BatchNormal (None, 8, 8, 128)    512         decoder_stage0a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_relu (Activatio (None, 8, 8, 128)    0           decoder_stage0a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_upsampling (UpSa (None, 16, 16, 128)  0           decoder_stage0a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_conv (Conv2D)   (None, 16, 16, 128)  147456      decoder_stage0_upsampling[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_bn (BatchNormal (None, 16, 16, 128)  512         decoder_stage0b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_relu (Activatio (None, 16, 16, 128)  0           decoder_stage0b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0c_conv (Conv2D)   (None, 16, 16, 512)  65536       decoder_stage0b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0c_bn (BatchNormal (None, 16, 16, 512)  2048        decoder_stage0c_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0c_relu (Activatio (None, 16, 16, 512)  0           decoder_stage0c_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_add (Add)        (None, 16, 16, 512)  0           decoder_stage0c_relu[0][0]       \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_conv (Conv2D)   (None, 16, 16, 128)  65536       decoder_stage0_add[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_bn (BatchNormal (None, 16, 16, 128)  512         decoder_stage1a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_relu (Activatio (None, 16, 16, 128)  0           decoder_stage1a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_upsampling (UpSa (None, 32, 32, 128)  0           decoder_stage1a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_conv (Conv2D)   (None, 32, 32, 128)  147456      decoder_stage1_upsampling[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_bn (BatchNormal (None, 32, 32, 128)  512         decoder_stage1b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_relu (Activatio (None, 32, 32, 128)  0           decoder_stage1b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1c_conv (Conv2D)   (None, 32, 32, 512)  65536       decoder_stage1b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1c_bn (BatchNormal (None, 32, 32, 512)  2048        decoder_stage1c_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1c_relu (Activatio (None, 32, 32, 512)  0           decoder_stage1c_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_add (Add)        (None, 32, 32, 512)  0           decoder_stage1c_relu[0][0]       \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_conv (Conv2D)   (None, 32, 32, 128)  65536       decoder_stage1_add[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_bn (BatchNormal (None, 32, 32, 128)  512         decoder_stage2a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_relu (Activatio (None, 32, 32, 128)  0           decoder_stage2a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_upsampling (UpSa (None, 64, 64, 128)  0           decoder_stage2a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_conv (Conv2D)   (None, 64, 64, 128)  147456      decoder_stage2_upsampling[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_bn (BatchNormal (None, 64, 64, 128)  512         decoder_stage2b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_relu (Activatio (None, 64, 64, 128)  0           decoder_stage2b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2c_conv (Conv2D)   (None, 64, 64, 256)  32768       decoder_stage2b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2c_bn (BatchNormal (None, 64, 64, 256)  1024        decoder_stage2c_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2c_relu (Activatio (None, 64, 64, 256)  0           decoder_stage2c_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_add (Add)        (None, 64, 64, 256)  0           decoder_stage2c_relu[0][0]       \n",
            "                                                                 block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_conv (Conv2D)   (None, 64, 64, 64)   16384       decoder_stage2_add[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_bn (BatchNormal (None, 64, 64, 64)   256         decoder_stage3a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_relu (Activatio (None, 64, 64, 64)   0           decoder_stage3a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_upsampling (UpSa (None, 128, 128, 64) 0           decoder_stage3a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_conv (Conv2D)   (None, 128, 128, 64) 36864       decoder_stage3_upsampling[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_bn (BatchNormal (None, 128, 128, 64) 256         decoder_stage3b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_relu (Activatio (None, 128, 128, 64) 0           decoder_stage3b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3c_conv (Conv2D)   (None, 128, 128, 128 8192        decoder_stage3b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3c_bn (BatchNormal (None, 128, 128, 128 512         decoder_stage3c_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3c_relu (Activatio (None, 128, 128, 128 0           decoder_stage3c_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_add (Add)        (None, 128, 128, 128 0           decoder_stage3c_relu[0][0]       \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_conv (Conv2D)   (None, 128, 128, 32) 4096        decoder_stage3_add[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_bn (BatchNormal (None, 128, 128, 32) 128         decoder_stage4a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_relu (Activatio (None, 128, 128, 32) 0           decoder_stage4a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_upsampling (UpSa (None, 256, 256, 32) 0           decoder_stage4a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_conv (Conv2D)   (None, 256, 256, 32) 9216        decoder_stage4_upsampling[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_bn (BatchNormal (None, 256, 256, 32) 128         decoder_stage4b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_relu (Activatio (None, 256, 256, 32) 0           decoder_stage4b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4c_conv (Conv2D)   (None, 256, 256, 16) 512         decoder_stage4b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4c_bn (BatchNormal (None, 256, 256, 16) 64          decoder_stage4c_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4c_relu (Activatio (None, 256, 256, 16) 0           decoder_stage4c_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 3)  435         decoder_stage4c_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sigmoid (Activation)            (None, 256, 256, 3)  0           conv2d_2[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 20,325,427\n",
            "Trainable params: 5,603,923\n",
            "Non-trainable params: 14,721,504\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from segmentation_models import Linknet\n",
        "\n",
        "model = Linknet(encoder_weights='imagenet', encoder_freeze=True, input_shape=(256, 256,3),classes=3)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQFYqxEzXpuC",
        "outputId": "4f932311-9f46-4d70-e37b-7908fa598281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 92 samples, validate on 23 samples\n",
            "Epoch 1/300\n",
            "92/92 [==============================] - 13s 145ms/step - loss: -279.4435 - accuracy: 0.0623 - val_loss: -7748.2751 - val_accuracy: 0.0226\n",
            "Epoch 2/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -1233.0832 - accuracy: 0.0240 - val_loss: -9286.3392 - val_accuracy: 0.0226\n",
            "Epoch 3/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -2681.8421 - accuracy: 0.0178 - val_loss: -2665.9602 - val_accuracy: 0.0226\n",
            "Epoch 4/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -4497.6009 - accuracy: 0.0178 - val_loss: -5742.8815 - val_accuracy: 0.0226\n",
            "Epoch 5/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -6649.5443 - accuracy: 0.0178 - val_loss: -10231.3459 - val_accuracy: 0.0226\n",
            "Epoch 6/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -9157.9130 - accuracy: 0.0178 - val_loss: -13667.8236 - val_accuracy: 0.0226\n",
            "Epoch 7/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -12091.1882 - accuracy: 0.0178 - val_loss: -1164.4508 - val_accuracy: 0.0226\n",
            "Epoch 8/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -15496.5904 - accuracy: 0.0178 - val_loss: -66.9280 - val_accuracy: 0.0226\n",
            "Epoch 9/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -19561.8802 - accuracy: 0.0178 - val_loss: -73.9551 - val_accuracy: 0.0226\n",
            "Epoch 10/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -24012.7956 - accuracy: 0.0178 - val_loss: -82.1376 - val_accuracy: 0.0226\n",
            "Epoch 11/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -29027.2006 - accuracy: 0.0178 - val_loss: -90.5580 - val_accuracy: 0.0226\n",
            "Epoch 12/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -34482.2644 - accuracy: 0.0178 - val_loss: -98.6757 - val_accuracy: 0.0226\n",
            "Epoch 13/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -40338.9034 - accuracy: 0.0178 - val_loss: -107.7418 - val_accuracy: 0.0226\n",
            "Epoch 14/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -46500.6857 - accuracy: 0.0178 - val_loss: -596.5901 - val_accuracy: 0.0226\n",
            "Epoch 15/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -53491.5533 - accuracy: 0.0178 - val_loss: -4553.1847 - val_accuracy: 0.0226\n",
            "Epoch 16/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -60503.6881 - accuracy: 0.0178 - val_loss: -6116.2493 - val_accuracy: 0.0226\n",
            "Epoch 17/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -67927.1762 - accuracy: 0.0178 - val_loss: -39152.8482 - val_accuracy: 0.0226\n",
            "Epoch 18/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -75968.5887 - accuracy: 0.0178 - val_loss: -54061.1948 - val_accuracy: 0.0226\n",
            "Epoch 19/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -84320.7201 - accuracy: 0.0178 - val_loss: -98663.9942 - val_accuracy: 0.0226\n",
            "Epoch 20/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -93059.0100 - accuracy: 0.0178 - val_loss: -65016.5499 - val_accuracy: 0.0226\n",
            "Epoch 21/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -102284.6011 - accuracy: 0.0178 - val_loss: -79366.1729 - val_accuracy: 0.0226\n",
            "Epoch 22/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -111823.8616 - accuracy: 0.0178 - val_loss: -110749.3916 - val_accuracy: 0.0226\n",
            "Epoch 23/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -121717.1471 - accuracy: 0.0178 - val_loss: -119447.1175 - val_accuracy: 0.0226\n",
            "Epoch 24/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -132179.3366 - accuracy: 0.0178 - val_loss: -155183.7806 - val_accuracy: 0.0226\n",
            "Epoch 25/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -142536.6481 - accuracy: 0.0178 - val_loss: -147034.7812 - val_accuracy: 0.0226\n",
            "Epoch 26/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -153587.9310 - accuracy: 0.0178 - val_loss: -172230.4042 - val_accuracy: 0.0226\n",
            "Epoch 27/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -164758.4558 - accuracy: 0.0178 - val_loss: -160282.6943 - val_accuracy: 0.0226\n",
            "Epoch 28/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -176281.8940 - accuracy: 0.0178 - val_loss: -175139.7962 - val_accuracy: 0.0226\n",
            "Epoch 29/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -188462.3471 - accuracy: 0.0178 - val_loss: -145338.8485 - val_accuracy: 0.0226\n",
            "Epoch 30/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -199927.1834 - accuracy: 0.0178 - val_loss: -214184.2894 - val_accuracy: 0.0226\n",
            "Epoch 31/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -213582.1399 - accuracy: 0.0178 - val_loss: -219189.2092 - val_accuracy: 0.0226\n",
            "Epoch 32/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -225961.9694 - accuracy: 0.0178 - val_loss: -248455.3098 - val_accuracy: 0.0226\n",
            "Epoch 33/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -238863.1328 - accuracy: 0.0178 - val_loss: -214385.5204 - val_accuracy: 0.0226\n",
            "Epoch 34/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -252280.8974 - accuracy: 0.0178 - val_loss: -214036.6399 - val_accuracy: 0.0226\n",
            "Epoch 35/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -267228.8971 - accuracy: 0.0178 - val_loss: -262016.2717 - val_accuracy: 0.0226\n",
            "Epoch 36/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -281273.8526 - accuracy: 0.0178 - val_loss: -276343.4130 - val_accuracy: 0.0226\n",
            "Epoch 37/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -295687.1304 - accuracy: 0.0178 - val_loss: -289967.9307 - val_accuracy: 0.0226\n",
            "Epoch 38/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -310709.5292 - accuracy: 0.0178 - val_loss: -299310.1522 - val_accuracy: 0.0226\n",
            "Epoch 39/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -325599.8614 - accuracy: 0.0178 - val_loss: -307601.7772 - val_accuracy: 0.0226\n",
            "Epoch 40/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -341100.4959 - accuracy: 0.0178 - val_loss: -318807.3397 - val_accuracy: 0.0226\n",
            "Epoch 41/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -357488.1549 - accuracy: 0.0178 - val_loss: -299077.0204 - val_accuracy: 0.0226\n",
            "Epoch 42/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -373117.0978 - accuracy: 0.0178 - val_loss: -363240.7120 - val_accuracy: 0.0226\n",
            "Epoch 43/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -389336.4022 - accuracy: 0.0178 - val_loss: -355292.9633 - val_accuracy: 0.0226\n",
            "Epoch 44/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -406109.8030 - accuracy: 0.0178 - val_loss: -385719.1916 - val_accuracy: 0.0226\n",
            "Epoch 45/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -422886.5679 - accuracy: 0.0178 - val_loss: -407876.6902 - val_accuracy: 0.0226\n",
            "Epoch 46/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -439210.9932 - accuracy: 0.0178 - val_loss: -402200.6576 - val_accuracy: 0.0226\n",
            "Epoch 47/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -456802.9728 - accuracy: 0.0178 - val_loss: -457493.0027 - val_accuracy: 0.0226\n",
            "Epoch 48/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -475277.3682 - accuracy: 0.0178 - val_loss: -448662.7894 - val_accuracy: 0.0226\n",
            "Epoch 49/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -492262.9796 - accuracy: 0.0178 - val_loss: -451200.1182 - val_accuracy: 0.0226\n",
            "Epoch 50/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -510458.8030 - accuracy: 0.0178 - val_loss: -514102.8030 - val_accuracy: 0.0226\n",
            "Epoch 51/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -529202.9232 - accuracy: 0.0178 - val_loss: -522829.1916 - val_accuracy: 0.0226\n",
            "Epoch 52/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -547736.4592 - accuracy: 0.0178 - val_loss: -528800.3736 - val_accuracy: 0.0226\n",
            "Epoch 53/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -566888.4117 - accuracy: 0.0178 - val_loss: -494682.5924 - val_accuracy: 0.0226\n",
            "Epoch 54/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -586955.6481 - accuracy: 0.0178 - val_loss: -563672.1223 - val_accuracy: 0.0226\n",
            "Epoch 55/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -606434.9592 - accuracy: 0.0178 - val_loss: -609844.4728 - val_accuracy: 0.0226\n",
            "Epoch 56/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -625987.8981 - accuracy: 0.0178 - val_loss: -579630.2337 - val_accuracy: 0.0226\n",
            "Epoch 57/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -644720.7296 - accuracy: 0.0178 - val_loss: -631439.1223 - val_accuracy: 0.0226\n",
            "Epoch 58/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -665943.8927 - accuracy: 0.0178 - val_loss: -607503.7174 - val_accuracy: 0.0226\n",
            "Epoch 59/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -687801.8940 - accuracy: 0.0178 - val_loss: -647393.9620 - val_accuracy: 0.0226\n",
            "Epoch 60/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -708533.7147 - accuracy: 0.0178 - val_loss: -631395.8859 - val_accuracy: 0.0226\n",
            "Epoch 61/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -728783.3995 - accuracy: 0.0178 - val_loss: -677906.3098 - val_accuracy: 0.0226\n",
            "Epoch 62/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -750151.9212 - accuracy: 0.0178 - val_loss: -651845.3098 - val_accuracy: 0.0226\n",
            "Epoch 63/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -770517.5258 - accuracy: 0.0178 - val_loss: -723168.3804 - val_accuracy: 0.0226\n",
            "Epoch 64/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -792562.4198 - accuracy: 0.0178 - val_loss: -692096.7826 - val_accuracy: 0.0226\n",
            "Epoch 65/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -815687.9755 - accuracy: 0.0178 - val_loss: -744318.2446 - val_accuracy: 0.0226\n",
            "Epoch 66/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -837988.2677 - accuracy: 0.0178 - val_loss: -781802.8098 - val_accuracy: 0.0226\n",
            "Epoch 67/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -859487.4891 - accuracy: 0.0178 - val_loss: -793486.7745 - val_accuracy: 0.0226\n",
            "Epoch 68/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -882173.9715 - accuracy: 0.0178 - val_loss: -732256.6087 - val_accuracy: 0.0226\n",
            "Epoch 69/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -905064.6087 - accuracy: 0.0178 - val_loss: -801638.3967 - val_accuracy: 0.0226\n",
            "Epoch 70/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -930252.8030 - accuracy: 0.0178 - val_loss: -832048.0978 - val_accuracy: 0.0226\n",
            "Epoch 71/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -952325.3098 - accuracy: 0.0178 - val_loss: -868698.1685 - val_accuracy: 0.0226\n",
            "Epoch 72/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -976283.0938 - accuracy: 0.0178 - val_loss: -883991.5679 - val_accuracy: 0.0226\n",
            "Epoch 73/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -1000282.0693 - accuracy: 0.0178 - val_loss: -873896.7065 - val_accuracy: 0.0226\n",
            "Epoch 74/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -1025130.5489 - accuracy: 0.0178 - val_loss: -912631.5870 - val_accuracy: 0.0226\n",
            "Epoch 75/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -1049200.4620 - accuracy: 0.0178 - val_loss: -910413.6033 - val_accuracy: 0.0226\n",
            "Epoch 76/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1073174.3872 - accuracy: 0.0178 - val_loss: -952607.0109 - val_accuracy: 0.0226\n",
            "Epoch 77/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1097654.4008 - accuracy: 0.0178 - val_loss: -984040.2853 - val_accuracy: 0.0226\n",
            "Epoch 78/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1123049.3111 - accuracy: 0.0178 - val_loss: -1024223.2935 - val_accuracy: 0.0226\n",
            "Epoch 79/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1148526.9592 - accuracy: 0.0178 - val_loss: -1004009.7120 - val_accuracy: 0.0226\n",
            "Epoch 80/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1172989.3533 - accuracy: 0.0178 - val_loss: -1037415.7935 - val_accuracy: 0.0226\n",
            "Epoch 81/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1199418.2065 - accuracy: 0.0178 - val_loss: -1054533.6223 - val_accuracy: 0.0226\n",
            "Epoch 82/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1225813.7364 - accuracy: 0.0178 - val_loss: -1071930.6196 - val_accuracy: 0.0226\n",
            "Epoch 83/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1249376.9375 - accuracy: 0.0178 - val_loss: -1087704.4348 - val_accuracy: 0.0226\n",
            "Epoch 84/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1277019.4647 - accuracy: 0.0178 - val_loss: -1107053.8370 - val_accuracy: 0.0226\n",
            "Epoch 85/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1302755.1875 - accuracy: 0.0178 - val_loss: -1185013.8207 - val_accuracy: 0.0226\n",
            "Epoch 86/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1328884.5163 - accuracy: 0.0178 - val_loss: -1173851.7011 - val_accuracy: 0.0226\n",
            "Epoch 87/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1355385.1141 - accuracy: 0.0178 - val_loss: -1101851.8478 - val_accuracy: 0.0226\n",
            "Epoch 88/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1382466.2527 - accuracy: 0.0178 - val_loss: -1204592.1522 - val_accuracy: 0.0226\n",
            "Epoch 89/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1408940.0761 - accuracy: 0.0178 - val_loss: -1163992.9130 - val_accuracy: 0.0226\n",
            "Epoch 90/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1438646.8750 - accuracy: 0.0178 - val_loss: -1211998.2880 - val_accuracy: 0.0226\n",
            "Epoch 91/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1469698.2446 - accuracy: 0.0178 - val_loss: -1274571.7120 - val_accuracy: 0.0226\n",
            "Epoch 92/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1497945.0761 - accuracy: 0.0178 - val_loss: -1280600.4022 - val_accuracy: 0.0226\n",
            "Epoch 93/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -1524125.5897 - accuracy: 0.0178 - val_loss: -1293464.0054 - val_accuracy: 0.0226\n",
            "Epoch 94/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1552813.1549 - accuracy: 0.0178 - val_loss: -1314053.4728 - val_accuracy: 0.0226\n",
            "Epoch 95/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1579278.2038 - accuracy: 0.0178 - val_loss: -1367311.5272 - val_accuracy: 0.0226\n",
            "Epoch 96/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1608776.5870 - accuracy: 0.0178 - val_loss: -1357293.2717 - val_accuracy: 0.0226\n",
            "Epoch 97/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1640898.2582 - accuracy: 0.0178 - val_loss: -1435533.6957 - val_accuracy: 0.0226\n",
            "Epoch 98/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1669757.9457 - accuracy: 0.0178 - val_loss: -1448393.2283 - val_accuracy: 0.0226\n",
            "Epoch 99/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1698877.8288 - accuracy: 0.0178 - val_loss: -1462962.7120 - val_accuracy: 0.0226\n",
            "Epoch 100/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1726562.6739 - accuracy: 0.0178 - val_loss: -1500484.1196 - val_accuracy: 0.0226\n",
            "Epoch 101/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1757508.6168 - accuracy: 0.0178 - val_loss: -1445902.9293 - val_accuracy: 0.0226\n",
            "Epoch 102/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -1787992.2391 - accuracy: 0.0178 - val_loss: -1578879.2391 - val_accuracy: 0.0226\n",
            "Epoch 103/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1817932.0272 - accuracy: 0.0178 - val_loss: -1614198.2935 - val_accuracy: 0.0226\n",
            "Epoch 104/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -1850273.8071 - accuracy: 0.0178 - val_loss: -1618142.2065 - val_accuracy: 0.0226\n",
            "Epoch 105/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -1881348.4674 - accuracy: 0.0178 - val_loss: -1651643.4728 - val_accuracy: 0.0226\n",
            "Epoch 106/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -1912425.1848 - accuracy: 0.0178 - val_loss: -1645935.6848 - val_accuracy: 0.0226\n",
            "Epoch 107/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -1940790.7337 - accuracy: 0.0178 - val_loss: -1631557.1250 - val_accuracy: 0.0226\n",
            "Epoch 108/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -1974163.4647 - accuracy: 0.0178 - val_loss: -1647265.3804 - val_accuracy: 0.0226\n",
            "Epoch 109/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2004575.3342 - accuracy: 0.0178 - val_loss: -1734810.0652 - val_accuracy: 0.0226\n",
            "Epoch 110/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2038271.1359 - accuracy: 0.0178 - val_loss: -1801609.8261 - val_accuracy: 0.0226\n",
            "Epoch 111/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2067981.7065 - accuracy: 0.0178 - val_loss: -1720587.3370 - val_accuracy: 0.0226\n",
            "Epoch 112/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2099719.0027 - accuracy: 0.0178 - val_loss: -1897454.3261 - val_accuracy: 0.0226\n",
            "Epoch 113/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2133361.7989 - accuracy: 0.0178 - val_loss: -1959236.9457 - val_accuracy: 0.0226\n",
            "Epoch 114/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2165356.3261 - accuracy: 0.0178 - val_loss: -1873942.4239 - val_accuracy: 0.0226\n",
            "Epoch 115/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2201991.9348 - accuracy: 0.0178 - val_loss: -1837921.2826 - val_accuracy: 0.0226\n",
            "Epoch 116/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2230109.8451 - accuracy: 0.0178 - val_loss: -1981063.9783 - val_accuracy: 0.0226\n",
            "Epoch 117/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2267836.9185 - accuracy: 0.0178 - val_loss: -1980336.3098 - val_accuracy: 0.0226\n",
            "Epoch 118/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -2301144.7255 - accuracy: 0.0178 - val_loss: -2059228.8587 - val_accuracy: 0.0226\n",
            "Epoch 119/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2333845.2120 - accuracy: 0.0178 - val_loss: -1985207.0652 - val_accuracy: 0.0226\n",
            "Epoch 120/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2365149.8424 - accuracy: 0.0178 - val_loss: -2015419.0435 - val_accuracy: 0.0226\n",
            "Epoch 121/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2401159.1685 - accuracy: 0.0178 - val_loss: -2080259.9565 - val_accuracy: 0.0226\n",
            "Epoch 122/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -2435353.7935 - accuracy: 0.0178 - val_loss: -2131366.7609 - val_accuracy: 0.0226\n",
            "Epoch 123/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -2468868.7120 - accuracy: 0.0178 - val_loss: -2142872.6522 - val_accuracy: 0.0226\n",
            "Epoch 124/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -2502091.9185 - accuracy: 0.0178 - val_loss: -2066667.6957 - val_accuracy: 0.0226\n",
            "Epoch 125/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2539231.1902 - accuracy: 0.0178 - val_loss: -2171493.0000 - val_accuracy: 0.0226\n",
            "Epoch 126/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2577973.2500 - accuracy: 0.0178 - val_loss: -2132844.6522 - val_accuracy: 0.0226\n",
            "Epoch 127/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2607935.9837 - accuracy: 0.0178 - val_loss: -2322484.8261 - val_accuracy: 0.0226\n",
            "Epoch 128/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -2644516.8750 - accuracy: 0.0178 - val_loss: -2338588.5217 - val_accuracy: 0.0226\n",
            "Epoch 129/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2680601.6467 - accuracy: 0.0178 - val_loss: -2274467.0761 - val_accuracy: 0.0226\n",
            "Epoch 130/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2717008.4076 - accuracy: 0.0178 - val_loss: -2507124.9239 - val_accuracy: 0.0226\n",
            "Epoch 131/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -2754735.7609 - accuracy: 0.0178 - val_loss: -2415600.4565 - val_accuracy: 0.0226\n",
            "Epoch 132/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2788382.5489 - accuracy: 0.0178 - val_loss: -2410933.5543 - val_accuracy: 0.0226\n",
            "Epoch 133/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2827784.2120 - accuracy: 0.0178 - val_loss: -2427525.2391 - val_accuracy: 0.0226\n",
            "Epoch 134/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -2866696.0380 - accuracy: 0.0178 - val_loss: -2476874.9783 - val_accuracy: 0.0226\n",
            "Epoch 135/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -2902432.4457 - accuracy: 0.0178 - val_loss: -2560660.0978 - val_accuracy: 0.0226\n",
            "Epoch 136/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -2937839.0489 - accuracy: 0.0178 - val_loss: -2538841.6957 - val_accuracy: 0.0226\n",
            "Epoch 137/300\n",
            "92/92 [==============================] - 4s 40ms/step - loss: -2971260.6576 - accuracy: 0.0178 - val_loss: -2623561.3152 - val_accuracy: 0.0226\n",
            "Epoch 138/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3007555.6196 - accuracy: 0.0178 - val_loss: -2608312.7826 - val_accuracy: 0.0226\n",
            "Epoch 139/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3046698.9185 - accuracy: 0.0178 - val_loss: -2651035.8696 - val_accuracy: 0.0226\n",
            "Epoch 140/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3089442.0054 - accuracy: 0.0178 - val_loss: -2689833.1739 - val_accuracy: 0.0226\n",
            "Epoch 141/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3126734.1304 - accuracy: 0.0178 - val_loss: -2664901.5652 - val_accuracy: 0.0226\n",
            "Epoch 142/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3166514.9402 - accuracy: 0.0178 - val_loss: -2710233.0000 - val_accuracy: 0.0226\n",
            "Epoch 143/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3200716.5217 - accuracy: 0.0178 - val_loss: -2717820.8913 - val_accuracy: 0.0226\n",
            "Epoch 144/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3242487.3533 - accuracy: 0.0178 - val_loss: -2795159.0435 - val_accuracy: 0.0226\n",
            "Epoch 145/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3281978.1413 - accuracy: 0.0178 - val_loss: -2802045.8913 - val_accuracy: 0.0226\n",
            "Epoch 146/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3321458.5652 - accuracy: 0.0178 - val_loss: -2751526.9457 - val_accuracy: 0.0226\n",
            "Epoch 147/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3356087.7174 - accuracy: 0.0178 - val_loss: -2945914.7826 - val_accuracy: 0.0226\n",
            "Epoch 148/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3399596.8043 - accuracy: 0.0178 - val_loss: -2981961.6196 - val_accuracy: 0.0226\n",
            "Epoch 149/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3435955.3098 - accuracy: 0.0178 - val_loss: -3038606.7174 - val_accuracy: 0.0226\n",
            "Epoch 150/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3473285.6630 - accuracy: 0.0178 - val_loss: -2729194.5217 - val_accuracy: 0.0226\n",
            "Epoch 151/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3508596.4946 - accuracy: 0.0178 - val_loss: -3273828.8696 - val_accuracy: 0.0226\n",
            "Epoch 152/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3552141.9946 - accuracy: 0.0178 - val_loss: -3150814.6087 - val_accuracy: 0.0226\n",
            "Epoch 153/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3594041.7609 - accuracy: 0.0178 - val_loss: -3128863.9674 - val_accuracy: 0.0226\n",
            "Epoch 154/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3639259.8478 - accuracy: 0.0178 - val_loss: -3209641.0870 - val_accuracy: 0.0226\n",
            "Epoch 155/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3676552.9076 - accuracy: 0.0178 - val_loss: -3147120.4348 - val_accuracy: 0.0226\n",
            "Epoch 156/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3720205.1793 - accuracy: 0.0178 - val_loss: -3166938.5000 - val_accuracy: 0.0226\n",
            "Epoch 157/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3760145.2717 - accuracy: 0.0178 - val_loss: -3265020.3152 - val_accuracy: 0.0226\n",
            "Epoch 158/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3797782.7554 - accuracy: 0.0178 - val_loss: -3178018.1739 - val_accuracy: 0.0226\n",
            "Epoch 159/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -3842728.4239 - accuracy: 0.0178 - val_loss: -3281244.3261 - val_accuracy: 0.0226\n",
            "Epoch 160/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3887784.3478 - accuracy: 0.0178 - val_loss: -3392254.6196 - val_accuracy: 0.0226\n",
            "Epoch 161/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3927483.9076 - accuracy: 0.0178 - val_loss: -3291953.9348 - val_accuracy: 0.0226\n",
            "Epoch 162/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -3963676.0543 - accuracy: 0.0178 - val_loss: -3464508.7826 - val_accuracy: 0.0226\n",
            "Epoch 163/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4011544.3043 - accuracy: 0.0178 - val_loss: -3339151.4674 - val_accuracy: 0.0226\n",
            "Epoch 164/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -4050633.0978 - accuracy: 0.0178 - val_loss: -3712693.1957 - val_accuracy: 0.0226\n",
            "Epoch 165/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -4092742.2826 - accuracy: 0.0178 - val_loss: -3448079.2391 - val_accuracy: 0.0226\n",
            "Epoch 166/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4141116.7663 - accuracy: 0.0178 - val_loss: -3411104.2391 - val_accuracy: 0.0226\n",
            "Epoch 167/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4181218.8043 - accuracy: 0.0178 - val_loss: -3716041.7174 - val_accuracy: 0.0226\n",
            "Epoch 168/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -4226091.6359 - accuracy: 0.0178 - val_loss: -3731168.1522 - val_accuracy: 0.0226\n",
            "Epoch 169/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -4276546.7826 - accuracy: 0.0178 - val_loss: -3708588.9783 - val_accuracy: 0.0226\n",
            "Epoch 170/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -4313801.4837 - accuracy: 0.0178 - val_loss: -3733771.1522 - val_accuracy: 0.0226\n",
            "Epoch 171/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4357053.7663 - accuracy: 0.0178 - val_loss: -3703376.4130 - val_accuracy: 0.0226\n",
            "Epoch 172/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4402791.5761 - accuracy: 0.0178 - val_loss: -3886481.9348 - val_accuracy: 0.0226\n",
            "Epoch 173/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -4446734.5435 - accuracy: 0.0178 - val_loss: -3845651.4565 - val_accuracy: 0.0226\n",
            "Epoch 174/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -4492630.0543 - accuracy: 0.0178 - val_loss: -3956900.4565 - val_accuracy: 0.0226\n",
            "Epoch 175/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4537910.7174 - accuracy: 0.0178 - val_loss: -3878713.7826 - val_accuracy: 0.0226\n",
            "Epoch 176/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4574334.0761 - accuracy: 0.0178 - val_loss: -3868264.0435 - val_accuracy: 0.0226\n",
            "Epoch 177/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -4624262.7935 - accuracy: 0.0178 - val_loss: -4093920.3696 - val_accuracy: 0.0226\n",
            "Epoch 178/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -4669193.8261 - accuracy: 0.0178 - val_loss: -4203860.3261 - val_accuracy: 0.0226\n",
            "Epoch 179/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4716133.3696 - accuracy: 0.0178 - val_loss: -4100047.9348 - val_accuracy: 0.0226\n",
            "Epoch 180/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -4764034.8478 - accuracy: 0.0178 - val_loss: -4072754.5217 - val_accuracy: 0.0226\n",
            "Epoch 181/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -4805019.4565 - accuracy: 0.0178 - val_loss: -4248617.5652 - val_accuracy: 0.0226\n",
            "Epoch 182/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4848125.7065 - accuracy: 0.0178 - val_loss: -4194266.5000 - val_accuracy: 0.0226\n",
            "Epoch 183/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4895789.5435 - accuracy: 0.0178 - val_loss: -4167492.9348 - val_accuracy: 0.0226\n",
            "Epoch 184/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -4946773.4239 - accuracy: 0.0178 - val_loss: -4217535.0000 - val_accuracy: 0.0226\n",
            "Epoch 185/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -4987693.2174 - accuracy: 0.0178 - val_loss: -4453436.2717 - val_accuracy: 0.0226\n",
            "Epoch 186/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -5025229.1304 - accuracy: 0.0178 - val_loss: -4448059.7174 - val_accuracy: 0.0226\n",
            "Epoch 187/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -5078765.5870 - accuracy: 0.0178 - val_loss: -4441993.6304 - val_accuracy: 0.0226\n",
            "Epoch 188/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -5129823.4239 - accuracy: 0.0178 - val_loss: -4633746.1087 - val_accuracy: 0.0226\n",
            "Epoch 189/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5179371.7935 - accuracy: 0.0178 - val_loss: -4447211.8261 - val_accuracy: 0.0226\n",
            "Epoch 190/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -5232798.0326 - accuracy: 0.0178 - val_loss: -4566955.3696 - val_accuracy: 0.0226\n",
            "Epoch 191/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5270650.9130 - accuracy: 0.0178 - val_loss: -4593007.8261 - val_accuracy: 0.0226\n",
            "Epoch 192/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5322218.4674 - accuracy: 0.0178 - val_loss: -4565551.7826 - val_accuracy: 0.0226\n",
            "Epoch 193/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5373591.2935 - accuracy: 0.0178 - val_loss: -4615807.7174 - val_accuracy: 0.0226\n",
            "Epoch 194/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5420325.1304 - accuracy: 0.0178 - val_loss: -4600877.0000 - val_accuracy: 0.0226\n",
            "Epoch 195/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5468990.3804 - accuracy: 0.0178 - val_loss: -4729245.3913 - val_accuracy: 0.0226\n",
            "Epoch 196/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5515345.5217 - accuracy: 0.0178 - val_loss: -4803983.8478 - val_accuracy: 0.0226\n",
            "Epoch 197/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5569561.3152 - accuracy: 0.0178 - val_loss: -4702450.4565 - val_accuracy: 0.0226\n",
            "Epoch 198/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5615988.8587 - accuracy: 0.0178 - val_loss: -4971347.6304 - val_accuracy: 0.0226\n",
            "Epoch 199/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -5669475.9348 - accuracy: 0.0178 - val_loss: -4909997.5217 - val_accuracy: 0.0226\n",
            "Epoch 200/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -5706428.6304 - accuracy: 0.0178 - val_loss: -5049842.2174 - val_accuracy: 0.0226\n",
            "Epoch 201/300\n",
            "92/92 [==============================] - 4s 40ms/step - loss: -5764196.2065 - accuracy: 0.0178 - val_loss: -5064059.6522 - val_accuracy: 0.0226\n",
            "Epoch 202/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5809559.9022 - accuracy: 0.0178 - val_loss: -5080497.2826 - val_accuracy: 0.0226\n",
            "Epoch 203/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -5864538.4348 - accuracy: 0.0178 - val_loss: -5084051.1304 - val_accuracy: 0.0226\n",
            "Epoch 204/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -5910400.8587 - accuracy: 0.0178 - val_loss: -5160902.2174 - val_accuracy: 0.0226\n",
            "Epoch 205/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -5966447.9348 - accuracy: 0.0178 - val_loss: -5389707.9565 - val_accuracy: 0.0226\n",
            "Epoch 206/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -6011242.9674 - accuracy: 0.0178 - val_loss: -5164907.1957 - val_accuracy: 0.0226\n",
            "Epoch 207/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -6060669.5761 - accuracy: 0.0178 - val_loss: -5430341.6087 - val_accuracy: 0.0226\n",
            "Epoch 208/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -6116738.2717 - accuracy: 0.0178 - val_loss: -5335642.6087 - val_accuracy: 0.0226\n",
            "Epoch 209/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -6166561.8478 - accuracy: 0.0178 - val_loss: -5234324.0000 - val_accuracy: 0.0226\n",
            "Epoch 210/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -6225945.5217 - accuracy: 0.0178 - val_loss: -5234389.2174 - val_accuracy: 0.0226\n",
            "Epoch 211/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -6264473.4674 - accuracy: 0.0178 - val_loss: -5453502.9348 - val_accuracy: 0.0226\n",
            "Epoch 212/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -6321411.3261 - accuracy: 0.0178 - val_loss: -5611450.9783 - val_accuracy: 0.0226\n",
            "Epoch 213/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -6368581.0761 - accuracy: 0.0178 - val_loss: -5502229.5870 - val_accuracy: 0.0226\n",
            "Epoch 214/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -6429268.2065 - accuracy: 0.0178 - val_loss: -5661820.7609 - val_accuracy: 0.0226\n",
            "Epoch 215/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -6473288.7065 - accuracy: 0.0178 - val_loss: -5647349.1739 - val_accuracy: 0.0226\n",
            "Epoch 216/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -6532073.0870 - accuracy: 0.0178 - val_loss: -5607220.9565 - val_accuracy: 0.0226\n",
            "Epoch 217/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -6580577.0326 - accuracy: 0.0178 - val_loss: -5550974.3696 - val_accuracy: 0.0226\n",
            "Epoch 218/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -6636584.4674 - accuracy: 0.0178 - val_loss: -5792174.2609 - val_accuracy: 0.0226\n",
            "Epoch 219/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -6687598.8370 - accuracy: 0.0178 - val_loss: -5938922.6087 - val_accuracy: 0.0226\n",
            "Epoch 220/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -6743168.5761 - accuracy: 0.0178 - val_loss: -5821855.3043 - val_accuracy: 0.0226\n",
            "Epoch 221/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -6800377.8370 - accuracy: 0.0178 - val_loss: -5645705.6522 - val_accuracy: 0.0226\n",
            "Epoch 222/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -6848041.7935 - accuracy: 0.0178 - val_loss: -6074669.8696 - val_accuracy: 0.0226\n",
            "Epoch 223/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -6899065.1630 - accuracy: 0.0178 - val_loss: -6067125.9565 - val_accuracy: 0.0226\n",
            "Epoch 224/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -6964111.9348 - accuracy: 0.0178 - val_loss: -6142977.4348 - val_accuracy: 0.0226\n",
            "Epoch 225/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7016367.9130 - accuracy: 0.0178 - val_loss: -5841871.5217 - val_accuracy: 0.0226\n",
            "Epoch 226/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7066896.2283 - accuracy: 0.0178 - val_loss: -6140080.1522 - val_accuracy: 0.0226\n",
            "Epoch 227/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7113912.1413 - accuracy: 0.0178 - val_loss: -6034749.5652 - val_accuracy: 0.0226\n",
            "Epoch 228/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7180606.3370 - accuracy: 0.0178 - val_loss: -6481872.8043 - val_accuracy: 0.0226\n",
            "Epoch 229/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7226570.1630 - accuracy: 0.0178 - val_loss: -6249903.2826 - val_accuracy: 0.0226\n",
            "Epoch 230/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7285851.0761 - accuracy: 0.0178 - val_loss: -6554056.4348 - val_accuracy: 0.0226\n",
            "Epoch 231/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7340940.7391 - accuracy: 0.0178 - val_loss: -6118518.2174 - val_accuracy: 0.0226\n",
            "Epoch 232/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7400092.9130 - accuracy: 0.0178 - val_loss: -6627684.9783 - val_accuracy: 0.0226\n",
            "Epoch 233/300\n",
            "92/92 [==============================] - 4s 40ms/step - loss: -7453764.3043 - accuracy: 0.0178 - val_loss: -6377325.0870 - val_accuracy: 0.0226\n",
            "Epoch 234/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7511105.8696 - accuracy: 0.0178 - val_loss: -6399099.1087 - val_accuracy: 0.0226\n",
            "Epoch 235/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7572056.3370 - accuracy: 0.0178 - val_loss: -6386230.7609 - val_accuracy: 0.0226\n",
            "Epoch 236/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7618012.3370 - accuracy: 0.0178 - val_loss: -6745002.8043 - val_accuracy: 0.0226\n",
            "Epoch 237/300\n",
            "92/92 [==============================] - 3s 37ms/step - loss: -7673642.2717 - accuracy: 0.0178 - val_loss: -6862767.5000 - val_accuracy: 0.0226\n",
            "Epoch 238/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7737354.0870 - accuracy: 0.0178 - val_loss: -6725380.4348 - val_accuracy: 0.0226\n",
            "Epoch 239/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7785704.2391 - accuracy: 0.0178 - val_loss: -6672353.4783 - val_accuracy: 0.0226\n",
            "Epoch 240/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7844963.3152 - accuracy: 0.0178 - val_loss: -7048422.8696 - val_accuracy: 0.0226\n",
            "Epoch 241/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7910029.8804 - accuracy: 0.0178 - val_loss: -7004630.6087 - val_accuracy: 0.0226\n",
            "Epoch 242/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -7963341.1739 - accuracy: 0.0178 - val_loss: -6930028.2391 - val_accuracy: 0.0226\n",
            "Epoch 243/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8029013.6739 - accuracy: 0.0178 - val_loss: -7025202.8478 - val_accuracy: 0.0226\n",
            "Epoch 244/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8083672.5652 - accuracy: 0.0178 - val_loss: -7255551.7826 - val_accuracy: 0.0226\n",
            "Epoch 245/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8138371.9239 - accuracy: 0.0178 - val_loss: -7086740.2174 - val_accuracy: 0.0226\n",
            "Epoch 246/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8212867.2826 - accuracy: 0.0178 - val_loss: -7007268.6087 - val_accuracy: 0.0226\n",
            "Epoch 247/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8259647.6848 - accuracy: 0.0178 - val_loss: -7082747.3478 - val_accuracy: 0.0226\n",
            "Epoch 248/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -8321852.6196 - accuracy: 0.0178 - val_loss: -7118846.4565 - val_accuracy: 0.0226\n",
            "Epoch 249/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -8374438.8370 - accuracy: 0.0178 - val_loss: -7401621.7826 - val_accuracy: 0.0226\n",
            "Epoch 250/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -8441344.0761 - accuracy: 0.0178 - val_loss: -7226745.1087 - val_accuracy: 0.0226\n",
            "Epoch 251/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8506030.7391 - accuracy: 0.0178 - val_loss: -7362098.3478 - val_accuracy: 0.0226\n",
            "Epoch 252/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8555171.2065 - accuracy: 0.0178 - val_loss: -7339383.0870 - val_accuracy: 0.0226\n",
            "Epoch 253/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8625200.6848 - accuracy: 0.0178 - val_loss: -7380636.5870 - val_accuracy: 0.0226\n",
            "Epoch 254/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8676511.0435 - accuracy: 0.0178 - val_loss: -7690378.2826 - val_accuracy: 0.0226\n",
            "Epoch 255/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8743919.2826 - accuracy: 0.0178 - val_loss: -7677686.3043 - val_accuracy: 0.0226\n",
            "Epoch 256/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -8789703.7500 - accuracy: 0.0178 - val_loss: -7661140.8261 - val_accuracy: 0.0226\n",
            "Epoch 257/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -8864047.9783 - accuracy: 0.0178 - val_loss: -7425219.4783 - val_accuracy: 0.0226\n",
            "Epoch 258/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -8917456.9022 - accuracy: 0.0178 - val_loss: -7728843.6087 - val_accuracy: 0.0226\n",
            "Epoch 259/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -8974584.7609 - accuracy: 0.0178 - val_loss: -7674893.4130 - val_accuracy: 0.0226\n",
            "Epoch 260/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -9041704.8043 - accuracy: 0.0178 - val_loss: -7959961.3261 - val_accuracy: 0.0226\n",
            "Epoch 261/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -9112554.4130 - accuracy: 0.0178 - val_loss: -7689590.1087 - val_accuracy: 0.0226\n",
            "Epoch 262/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -9159929.6087 - accuracy: 0.0178 - val_loss: -7916570.0217 - val_accuracy: 0.0226\n",
            "Epoch 263/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -9216221.1304 - accuracy: 0.0178 - val_loss: -8034694.6522 - val_accuracy: 0.0226\n",
            "Epoch 264/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -9269596.8261 - accuracy: 0.0178 - val_loss: -8082204.8696 - val_accuracy: 0.0226\n",
            "Epoch 265/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -9340135.3043 - accuracy: 0.0178 - val_loss: -8086131.3043 - val_accuracy: 0.0226\n",
            "Epoch 266/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -9396906.1304 - accuracy: 0.0178 - val_loss: -8010817.4783 - val_accuracy: 0.0226\n",
            "Epoch 267/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -9471923.3043 - accuracy: 0.0178 - val_loss: -8188603.2391 - val_accuracy: 0.0226\n",
            "Epoch 268/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -9537720.6304 - accuracy: 0.0178 - val_loss: -8256792.1304 - val_accuracy: 0.0226\n",
            "Epoch 269/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -9594912.1087 - accuracy: 0.0178 - val_loss: -8288293.3696 - val_accuracy: 0.0226\n",
            "Epoch 270/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -9663785.0217 - accuracy: 0.0178 - val_loss: -8322676.7826 - val_accuracy: 0.0226\n",
            "Epoch 271/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -9727573.5217 - accuracy: 0.0178 - val_loss: -8410598.7826 - val_accuracy: 0.0226\n",
            "Epoch 272/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -9798501.3478 - accuracy: 0.0178 - val_loss: -8569702.6087 - val_accuracy: 0.0226\n",
            "Epoch 273/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -9855452.0000 - accuracy: 0.0178 - val_loss: -8641499.6087 - val_accuracy: 0.0226\n",
            "Epoch 274/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -9916413.7609 - accuracy: 0.0178 - val_loss: -8577212.0435 - val_accuracy: 0.0226\n",
            "Epoch 275/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -9971641.3696 - accuracy: 0.0178 - val_loss: -8813969.0000 - val_accuracy: 0.0226\n",
            "Epoch 276/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -10039083.8261 - accuracy: 0.0178 - val_loss: -8916772.6087 - val_accuracy: 0.0226\n",
            "Epoch 277/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -10105028.7174 - accuracy: 0.0178 - val_loss: -8899172.1304 - val_accuracy: 0.0226\n",
            "Epoch 278/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -10169341.3696 - accuracy: 0.0178 - val_loss: -8889352.8261 - val_accuracy: 0.0226\n",
            "Epoch 279/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -10248271.6957 - accuracy: 0.0178 - val_loss: -8972303.4783 - val_accuracy: 0.0226\n",
            "Epoch 280/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -10291955.8043 - accuracy: 0.0178 - val_loss: -8731704.0000 - val_accuracy: 0.0226\n",
            "Epoch 281/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -10361042.6739 - accuracy: 0.0178 - val_loss: -8905979.2174 - val_accuracy: 0.0226\n",
            "Epoch 282/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -10418068.1087 - accuracy: 0.0178 - val_loss: -9031226.9130 - val_accuracy: 0.0226\n",
            "Epoch 283/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -10493181.3478 - accuracy: 0.0178 - val_loss: -9054927.5217 - val_accuracy: 0.0226\n",
            "Epoch 284/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -10557364.1957 - accuracy: 0.0178 - val_loss: -9201815.6522 - val_accuracy: 0.0226\n",
            "Epoch 285/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -10617171.2826 - accuracy: 0.0178 - val_loss: -9206494.9130 - val_accuracy: 0.0226\n",
            "Epoch 286/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -10698606.4783 - accuracy: 0.0178 - val_loss: -9285991.3043 - val_accuracy: 0.0226\n",
            "Epoch 287/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -10769956.6304 - accuracy: 0.0178 - val_loss: -9436678.7391 - val_accuracy: 0.0226\n",
            "Epoch 288/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -10807665.0652 - accuracy: 0.0178 - val_loss: -9905527.3043 - val_accuracy: 0.0226\n",
            "Epoch 289/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -10889222.2826 - accuracy: 0.0178 - val_loss: -9711194.4783 - val_accuracy: 0.0226\n",
            "Epoch 290/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -10948708.2609 - accuracy: 0.0178 - val_loss: -9427877.6957 - val_accuracy: 0.0226\n",
            "Epoch 291/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -11022874.2391 - accuracy: 0.0178 - val_loss: -9625331.7826 - val_accuracy: 0.0226\n",
            "Epoch 292/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -11089941.1739 - accuracy: 0.0178 - val_loss: -9357881.9565 - val_accuracy: 0.0226\n",
            "Epoch 293/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -11152380.4348 - accuracy: 0.0178 - val_loss: -9517604.3913 - val_accuracy: 0.0226\n",
            "Epoch 294/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -11228548.3043 - accuracy: 0.0178 - val_loss: -9756878.7826 - val_accuracy: 0.0226\n",
            "Epoch 295/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -11294897.2609 - accuracy: 0.0178 - val_loss: -9846805.5652 - val_accuracy: 0.0226\n",
            "Epoch 296/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -11358852.7391 - accuracy: 0.0178 - val_loss: -9940300.2609 - val_accuracy: 0.0226\n",
            "Epoch 297/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -11430321.2826 - accuracy: 0.0178 - val_loss: -9794980.5217 - val_accuracy: 0.0226\n",
            "Epoch 298/300\n",
            "92/92 [==============================] - 4s 39ms/step - loss: -11502749.3913 - accuracy: 0.0178 - val_loss: -10168019.7391 - val_accuracy: 0.0226\n",
            "Epoch 299/300\n",
            "92/92 [==============================] - 4s 38ms/step - loss: -11560480.6304 - accuracy: 0.0178 - val_loss: -10343462.5652 - val_accuracy: 0.0226\n",
            "Epoch 300/300\n",
            "92/92 [==============================] - 3s 38ms/step - loss: -11646409.6087 - accuracy: 0.0178 - val_loss: -10047855.1739 - val_accuracy: 0.0226\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_images, train_masks, batch_size=2, epochs=300, verbose=1, validation_data=(test_images, test_masks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WLnv7acaYA-R",
        "outputId": "e0877022-76ea-4af1-98e8-6aae80f06b57"
      },
      "outputs": [],
      "source": [
        "#accuracy = model.evaluate(x_val, y_val)\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('tight_LinkNet_Loss.jpg',dpi=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jQT2tgHQdNFM",
        "outputId": "ac78dd83-4917-4c4f-8beb-465047a58ba8"
      },
      "outputs": [],
      "source": [
        "#accuracy = model.evaluate(x_val, y_val)\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('tight_LinkNet_Accuracy.jpg',dpi=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xvaDNhmRbIJw"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Dataset/INbreast/checkpoint/breast_full/INBREAST_tight_LinkNet.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use trained model to predict masks (zip -> download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bRiuCz4BbZh_"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/Dataset/INbreast/checkpoint/breast_full/INBREAST_tight_LinkNet.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "lsGuvMWbiaTm"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0M81f5DigZO",
        "outputId": "d62bea48-9b75-4089-dc19-b30551e088dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23, 256, 256, 3)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2S9z8xQnijjC"
      },
      "outputs": [],
      "source": [
        "img_dir = os.listdir(\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/test/b/\")\n",
        "img_names = []\n",
        "for index,img_id in enumerate(img_dir):\n",
        "    img_names.append(img_id)\n",
        "\n",
        "i = 0\n",
        "for img_msk in prediction:\n",
        "    plt.imsave(f\"/content/sample_data/Result/{img_names[i]}\",img_msk,dpi=300)\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_w2bapEjiW1",
        "outputId": "5c035fa3-767c-4267-c110-f4f586ee5273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/sample_data/Result/ (stored 0%)\n",
            "  adding: content/sample_data/Result/20587758.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/20587994.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/2_51049107.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/20587612.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/2_20586908.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/20587664.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/2_22427840.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/20587902.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/2_22580341.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/20586934.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/2_22579730.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/2_22580367.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/20586908.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/2_20586960.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/20587810.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/20586986.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/20588216.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/20588046.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/2_24055464.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/20587928.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/20586960.jpeg (deflated 58%)\n",
            "  adding: content/sample_data/Result/2_22613770.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/20588190.jpeg (deflated 58%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/tight_Link.zip /content/sample_data/Result"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "INBreast_Segmentation_UNet.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e0de548ffb181fe2a01b2ed5f402e6bb6e6ccf2641efffae0817d36d41e1e10e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
