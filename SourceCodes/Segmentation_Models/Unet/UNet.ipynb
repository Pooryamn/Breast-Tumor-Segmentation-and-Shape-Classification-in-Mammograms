{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZLQid0ZDDNj",
        "outputId": "c7eee69d-7573-47ca-b086-0746baa8c75a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2kVf3xTEk3M",
        "outputId": "f8a3d002-6e85-4529-a5fa-20ffcab07437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation-models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.7.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.11.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation-models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d89IWx5eDo15"
      },
      "source": [
        "#Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW8U2we7VESL",
        "outputId": "8268bc33-aa48-4925-ee75-5f41492c6665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.2\n",
            "  Downloading tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 4.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.47.0)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.37.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.0)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.14.1)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.15.0)\n",
            "Collecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.1 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.1.0)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
            "\u001b[K     |████████████████████████████████| 454 kB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.21.6)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, scipy, h5py, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.4.1 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.14 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 scipy-1.4.1 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.3.1\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed keras-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segmentation-models in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.8)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.15.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip3 install tensorflow==2.2\n",
        "!pip3 install keras==2.3.1\n",
        "!pip3 install -U segmentation-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCRVXsNVVGUz",
        "outputId": "58474872-f75d-4eb8-9c32-78ce6b6a9888"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import segmentation_models as sm\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y-QZbAVjVjKC"
      },
      "outputs": [],
      "source": [
        "SIZE_Y = 256\n",
        "SIZE_X = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n9cwnmcWstA"
      },
      "source": [
        "# Load Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LaX9t8hDVk8T"
      },
      "outputs": [],
      "source": [
        "img_dir = os.listdir(\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/train/a/\")\n",
        "train_images = []\n",
        "for index,img_id in enumerate(img_dir):\n",
        "  img_path = f\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/train/a/{img_id}\"\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
        "  img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  train_images.append(img)\n",
        "  if index == 149:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l0JEqXl-V-ID"
      },
      "outputs": [],
      "source": [
        "train_images = np.array(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAVgWRsVWY7K",
        "outputId": "45f3a68f-465e-4347-c26e-874117581845"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(92, 256, 256, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UyyWgRSFWF7i"
      },
      "outputs": [],
      "source": [
        "img_dir = os.listdir(\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/train/b/\")\n",
        "train_masks = []\n",
        "for index,img_id in enumerate(img_dir):\n",
        "  img_path = f\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/train/b/{img_id}\"\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
        "  img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  train_masks.append(img)\n",
        "  if index == 149:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gMDkJwhpWWhy"
      },
      "outputs": [],
      "source": [
        "train_masks = np.array(train_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFO4dEIRWnRi",
        "outputId": "02cc0fa9-e8a7-4ccc-e359-849567a6bc6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(92, 256, 256, 3)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_masks.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e-YodNpWuqK"
      },
      "source": [
        "# Load Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CGcXEsc9WpzS"
      },
      "outputs": [],
      "source": [
        "img_dir = os.listdir(\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/test/a/\")\n",
        "test_images = []\n",
        "for index,img_id in enumerate(img_dir):\n",
        "  img_path = f\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/test/a/{img_id}\"\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
        "  img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  test_images.append(img)\n",
        "  if index == 149:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0hM3BpOFW2dL"
      },
      "outputs": [],
      "source": [
        "test_images = np.array(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYbSQ-tqXBLy",
        "outputId": "f0505021-62a1-4e7c-d5ba-4ac4837100d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23, 256, 256, 3)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I1CiskdlXFFC"
      },
      "outputs": [],
      "source": [
        "img_dir = os.listdir(\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/test/b/\")\n",
        "test_masks = []\n",
        "for index,img_id in enumerate(img_dir):\n",
        "  img_path = f\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/test/b/{img_id}\"\n",
        "  img = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
        "  img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "  test_masks.append(img)\n",
        "  if index == 149:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hH_CC2D1XOIj"
      },
      "outputs": [],
      "source": [
        "test_masks = np.array(test_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBTEZi-UXTZa",
        "outputId": "12495c64-e805-43db-cf15-b22abd03346a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23, 256, 256, 3)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_masks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nQ4PSXmGXVti"
      },
      "outputs": [],
      "source": [
        "# preprocess input\n",
        "train_images = preprocess_input(train_images)\n",
        "test_images = preprocess_input(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "N6fQY0hbXiba"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lAc_1Ag7Xk6a"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "IMG_CHANNELS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0z6-PPJrwH-",
        "outputId": "ba797fb9-4214-4af4-c6c2-0c8cc4ad1281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 8, 8, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_block1_conv (Conv2D)     (None, 8, 8, 512)    2359296     block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_block1_bn (BatchNormaliz (None, 8, 8, 512)    2048        center_block1_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_block1_relu (Activation) (None, 8, 8, 512)    0           center_block1_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "center_block2_conv (Conv2D)     (None, 8, 8, 512)    2359296     center_block1_relu[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_block2_bn (BatchNormaliz (None, 8, 8, 512)    2048        center_block2_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_block2_relu (Activation) (None, 8, 8, 512)    0           center_block2_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_upsampling (UpSa (None, 16, 16, 512)  0           center_block2_relu[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_concat (Concaten (None, 16, 16, 1024) 0           decoder_stage0_upsampling[0][0]  \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_conv (Conv2D)   (None, 16, 16, 256)  2359296     decoder_stage0_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_bn (BatchNormal (None, 16, 16, 256)  1024        decoder_stage0a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_relu (Activatio (None, 16, 16, 256)  0           decoder_stage0a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_conv (Conv2D)   (None, 16, 16, 256)  589824      decoder_stage0a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_bn (BatchNormal (None, 16, 16, 256)  1024        decoder_stage0b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_relu (Activatio (None, 16, 16, 256)  0           decoder_stage0b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_upsampling (UpSa (None, 32, 32, 256)  0           decoder_stage0b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_concat (Concaten (None, 32, 32, 768)  0           decoder_stage1_upsampling[0][0]  \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_conv (Conv2D)   (None, 32, 32, 128)  884736      decoder_stage1_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_bn (BatchNormal (None, 32, 32, 128)  512         decoder_stage1a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_relu (Activatio (None, 32, 32, 128)  0           decoder_stage1a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_conv (Conv2D)   (None, 32, 32, 128)  147456      decoder_stage1a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_bn (BatchNormal (None, 32, 32, 128)  512         decoder_stage1b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_relu (Activatio (None, 32, 32, 128)  0           decoder_stage1b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_upsampling (UpSa (None, 64, 64, 128)  0           decoder_stage1b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_concat (Concaten (None, 64, 64, 384)  0           decoder_stage2_upsampling[0][0]  \n",
            "                                                                 block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_conv (Conv2D)   (None, 64, 64, 64)   221184      decoder_stage2_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_bn (BatchNormal (None, 64, 64, 64)   256         decoder_stage2a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_relu (Activatio (None, 64, 64, 64)   0           decoder_stage2a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_conv (Conv2D)   (None, 64, 64, 64)   36864       decoder_stage2a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_bn (BatchNormal (None, 64, 64, 64)   256         decoder_stage2b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_relu (Activatio (None, 64, 64, 64)   0           decoder_stage2b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_upsampling (UpSa (None, 128, 128, 64) 0           decoder_stage2b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_concat (Concaten (None, 128, 128, 192 0           decoder_stage3_upsampling[0][0]  \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_conv (Conv2D)   (None, 128, 128, 32) 55296       decoder_stage3_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_bn (BatchNormal (None, 128, 128, 32) 128         decoder_stage3a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_relu (Activatio (None, 128, 128, 32) 0           decoder_stage3a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_conv (Conv2D)   (None, 128, 128, 32) 9216        decoder_stage3a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_bn (BatchNormal (None, 128, 128, 32) 128         decoder_stage3b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_relu (Activatio (None, 128, 128, 32) 0           decoder_stage3b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_upsampling (UpSa (None, 256, 256, 32) 0           decoder_stage3b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_conv (Conv2D)   (None, 256, 256, 16) 4608        decoder_stage4_upsampling[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_bn (BatchNormal (None, 256, 256, 16) 64          decoder_stage4a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_relu (Activatio (None, 256, 256, 16) 0           decoder_stage4a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_conv (Conv2D)   (None, 256, 256, 16) 2304        decoder_stage4a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_bn (BatchNormal (None, 256, 256, 16) 64          decoder_stage4b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_relu (Activatio (None, 256, 256, 16) 0           decoder_stage4b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "final_conv (Conv2D)             (None, 256, 256, 3)  435         decoder_stage4b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sigmoid (Activation)            (None, 256, 256, 3)  0           final_conv[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 23,752,563\n",
            "Trainable params: 9,033,843\n",
            "Non-trainable params: 14,718,720\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from segmentation_models import Unet\n",
        "\n",
        "model = Unet(encoder_weights='imagenet', encoder_freeze=True, input_shape=(256, 256,3),classes=3)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQFYqxEzXpuC",
        "outputId": "6ccbec3f-daf1-43f3-b2c7-3075901bbb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 92 samples, validate on 23 samples\n",
            "Epoch 1/300\n",
            "92/92 [==============================] - 12s 134ms/step - loss: -306.5607 - accuracy: 0.1025 - val_loss: -2791.0811 - val_accuracy: 0.0287\n",
            "Epoch 2/300\n",
            "92/92 [==============================] - 3s 31ms/step - loss: -1280.2182 - accuracy: 0.0364 - val_loss: -633.7738 - val_accuracy: 0.0235\n",
            "Epoch 3/300\n",
            "92/92 [==============================] - 3s 31ms/step - loss: -2813.4535 - accuracy: 0.0179 - val_loss: -27.7437 - val_accuracy: 0.0226\n",
            "Epoch 4/300\n",
            "92/92 [==============================] - 3s 31ms/step - loss: -4747.9978 - accuracy: 0.0178 - val_loss: -42.4921 - val_accuracy: 0.0226\n",
            "Epoch 5/300\n",
            "92/92 [==============================] - 3s 31ms/step - loss: -7053.1840 - accuracy: 0.0178 - val_loss: -4397.2229 - val_accuracy: 0.0226\n",
            "Epoch 6/300\n",
            "92/92 [==============================] - 3s 31ms/step - loss: -9752.7927 - accuracy: 0.0178 - val_loss: -173.4922 - val_accuracy: 0.0226\n",
            "Epoch 7/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -12851.6206 - accuracy: 0.0178 - val_loss: -17124.9139 - val_accuracy: 0.0226\n",
            "Epoch 8/300\n",
            "92/92 [==============================] - 3s 31ms/step - loss: -16386.2119 - accuracy: 0.0178 - val_loss: -65.2109 - val_accuracy: 0.0226\n",
            "Epoch 9/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -20363.2363 - accuracy: 0.0178 - val_loss: -364.4147 - val_accuracy: 0.0226\n",
            "Epoch 10/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -24746.8818 - accuracy: 0.0178 - val_loss: -31147.1157 - val_accuracy: 0.0226\n",
            "Epoch 11/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -29600.1628 - accuracy: 0.0178 - val_loss: -31574.2459 - val_accuracy: 0.0226\n",
            "Epoch 12/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -34821.9434 - accuracy: 0.0178 - val_loss: -52299.1766 - val_accuracy: 0.0226\n",
            "Epoch 13/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -40506.9029 - accuracy: 0.0178 - val_loss: -50986.7244 - val_accuracy: 0.0226\n",
            "Epoch 14/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -46706.0864 - accuracy: 0.0178 - val_loss: -8550.3177 - val_accuracy: 0.0226\n",
            "Epoch 15/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -53189.9478 - accuracy: 0.0178 - val_loss: -61716.8706 - val_accuracy: 0.0226\n",
            "Epoch 16/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -60074.2422 - accuracy: 0.0178 - val_loss: -27505.4322 - val_accuracy: 0.0226\n",
            "Epoch 17/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -67569.0430 - accuracy: 0.0178 - val_loss: -76702.8091 - val_accuracy: 0.0226\n",
            "Epoch 18/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -75344.2089 - accuracy: 0.0178 - val_loss: -69651.9871 - val_accuracy: 0.0226\n",
            "Epoch 19/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -83367.2240 - accuracy: 0.0178 - val_loss: -101029.9062 - val_accuracy: 0.0226\n",
            "Epoch 20/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -92120.8633 - accuracy: 0.0178 - val_loss: -79401.3451 - val_accuracy: 0.0226\n",
            "Epoch 21/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -100884.3616 - accuracy: 0.0178 - val_loss: -109051.3387 - val_accuracy: 0.0226\n",
            "Epoch 22/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -110408.7539 - accuracy: 0.0178 - val_loss: -103928.6420 - val_accuracy: 0.0226\n",
            "Epoch 23/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -120309.1564 - accuracy: 0.0178 - val_loss: -121052.8471 - val_accuracy: 0.0226\n",
            "Epoch 24/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -130244.3923 - accuracy: 0.0178 - val_loss: -139049.7880 - val_accuracy: 0.0226\n",
            "Epoch 25/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -140746.0238 - accuracy: 0.0178 - val_loss: -158270.9042 - val_accuracy: 0.0226\n",
            "Epoch 26/300\n",
            "92/92 [==============================] - 3s 32ms/step - loss: -151743.6301 - accuracy: 0.0178 - val_loss: -135640.1101 - val_accuracy: 0.0226\n",
            "Epoch 27/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -162764.0740 - accuracy: 0.0178 - val_loss: -178734.1576 - val_accuracy: 0.0226\n",
            "Epoch 28/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -174237.1179 - accuracy: 0.0178 - val_loss: -199280.4144 - val_accuracy: 0.0226\n",
            "Epoch 29/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -186181.3910 - accuracy: 0.0178 - val_loss: -207705.6039 - val_accuracy: 0.0226\n",
            "Epoch 30/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -198300.6885 - accuracy: 0.0178 - val_loss: -171566.3111 - val_accuracy: 0.0226\n",
            "Epoch 31/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -210945.6505 - accuracy: 0.0178 - val_loss: -195204.3872 - val_accuracy: 0.0226\n",
            "Epoch 32/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -223937.3682 - accuracy: 0.0178 - val_loss: -225735.7704 - val_accuracy: 0.0226\n",
            "Epoch 33/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -237028.2486 - accuracy: 0.0178 - val_loss: -219226.0815 - val_accuracy: 0.0226\n",
            "Epoch 34/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -251118.9440 - accuracy: 0.0178 - val_loss: -232995.2323 - val_accuracy: 0.0226\n",
            "Epoch 35/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -264732.3774 - accuracy: 0.0178 - val_loss: -233244.5734 - val_accuracy: 0.0226\n",
            "Epoch 36/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -279260.2405 - accuracy: 0.0178 - val_loss: -247313.7289 - val_accuracy: 0.0226\n",
            "Epoch 37/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -293736.4660 - accuracy: 0.0178 - val_loss: -278206.1495 - val_accuracy: 0.0226\n",
            "Epoch 38/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -308088.0340 - accuracy: 0.0178 - val_loss: -294928.3152 - val_accuracy: 0.0226\n",
            "Epoch 39/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -323261.9192 - accuracy: 0.0178 - val_loss: -308836.1916 - val_accuracy: 0.0226\n",
            "Epoch 40/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -338937.6223 - accuracy: 0.0178 - val_loss: -322356.9321 - val_accuracy: 0.0226\n",
            "Epoch 41/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -354325.4572 - accuracy: 0.0178 - val_loss: -264238.7840 - val_accuracy: 0.0226\n",
            "Epoch 42/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -370074.7969 - accuracy: 0.0178 - val_loss: -292655.2677 - val_accuracy: 0.0226\n",
            "Epoch 43/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -386766.3859 - accuracy: 0.0178 - val_loss: -311549.6332 - val_accuracy: 0.0226\n",
            "Epoch 44/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -403507.7772 - accuracy: 0.0178 - val_loss: -320531.1644 - val_accuracy: 0.0226\n",
            "Epoch 45/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -420363.6216 - accuracy: 0.0178 - val_loss: -295204.5367 - val_accuracy: 0.0226\n",
            "Epoch 46/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -437093.7283 - accuracy: 0.0178 - val_loss: -395133.0992 - val_accuracy: 0.0226\n",
            "Epoch 47/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -455155.8709 - accuracy: 0.0178 - val_loss: -438226.0503 - val_accuracy: 0.0226\n",
            "Epoch 48/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -472369.7079 - accuracy: 0.0178 - val_loss: -436399.1957 - val_accuracy: 0.0226\n",
            "Epoch 49/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -490305.9171 - accuracy: 0.0178 - val_loss: -420307.5149 - val_accuracy: 0.0226\n",
            "Epoch 50/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -508713.8016 - accuracy: 0.0178 - val_loss: -424695.0299 - val_accuracy: 0.0226\n",
            "Epoch 51/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -527367.1882 - accuracy: 0.0178 - val_loss: -538005.1114 - val_accuracy: 0.0226\n",
            "Epoch 52/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -545640.4864 - accuracy: 0.0178 - val_loss: -456976.8832 - val_accuracy: 0.0226\n",
            "Epoch 53/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -564503.3804 - accuracy: 0.0178 - val_loss: -427408.6046 - val_accuracy: 0.0226\n",
            "Epoch 54/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -582713.8872 - accuracy: 0.0178 - val_loss: -397801.4783 - val_accuracy: 0.0226\n",
            "Epoch 55/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -602798.5503 - accuracy: 0.0178 - val_loss: -513581.6630 - val_accuracy: 0.0226\n",
            "Epoch 56/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -623964.6033 - accuracy: 0.0178 - val_loss: -540432.0054 - val_accuracy: 0.0226\n",
            "Epoch 57/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -643725.6264 - accuracy: 0.0178 - val_loss: -611563.9212 - val_accuracy: 0.0226\n",
            "Epoch 58/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -663373.7690 - accuracy: 0.0178 - val_loss: -616403.7609 - val_accuracy: 0.0226\n",
            "Epoch 59/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -683975.3845 - accuracy: 0.0178 - val_loss: -1005221.9837 - val_accuracy: 0.0226\n",
            "Epoch 60/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -704941.1209 - accuracy: 0.0178 - val_loss: -503796.6535 - val_accuracy: 0.0226\n",
            "Epoch 61/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -724829.7880 - accuracy: 0.0178 - val_loss: -568570.3152 - val_accuracy: 0.0226\n",
            "Epoch 62/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -747342.3587 - accuracy: 0.0178 - val_loss: -571401.4728 - val_accuracy: 0.0226\n",
            "Epoch 63/300\n",
            "92/92 [==============================] - 3s 33ms/step - loss: -767984.9647 - accuracy: 0.0178 - val_loss: -605411.7609 - val_accuracy: 0.0226\n",
            "Epoch 64/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -788419.6372 - accuracy: 0.0178 - val_loss: -583772.8043 - val_accuracy: 0.0226\n",
            "Epoch 65/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -811529.6440 - accuracy: 0.0178 - val_loss: -644419.4864 - val_accuracy: 0.0226\n",
            "Epoch 66/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -833738.2514 - accuracy: 0.0178 - val_loss: -637035.1576 - val_accuracy: 0.0226\n",
            "Epoch 67/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -857257.3750 - accuracy: 0.0178 - val_loss: -725074.2935 - val_accuracy: 0.0226\n",
            "Epoch 68/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -878952.6562 - accuracy: 0.0178 - val_loss: -669832.2582 - val_accuracy: 0.0226\n",
            "Epoch 69/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -901475.0897 - accuracy: 0.0178 - val_loss: -703428.0652 - val_accuracy: 0.0226\n",
            "Epoch 70/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -925978.4171 - accuracy: 0.0178 - val_loss: -705949.6168 - val_accuracy: 0.0226\n",
            "Epoch 71/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -948884.1196 - accuracy: 0.0178 - val_loss: -787244.2772 - val_accuracy: 0.0226\n",
            "Epoch 72/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -973061.9375 - accuracy: 0.0178 - val_loss: -770090.5897 - val_accuracy: 0.0226\n",
            "Epoch 73/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -997218.2867 - accuracy: 0.0178 - val_loss: -809245.2663 - val_accuracy: 0.0226\n",
            "Epoch 74/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1021013.8872 - accuracy: 0.0178 - val_loss: -800611.3750 - val_accuracy: 0.0226\n",
            "Epoch 75/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1045145.4905 - accuracy: 0.0178 - val_loss: -919862.7799 - val_accuracy: 0.0226\n",
            "Epoch 76/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1068721.4008 - accuracy: 0.0178 - val_loss: -849062.1576 - val_accuracy: 0.0226\n",
            "Epoch 77/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1093997.0652 - accuracy: 0.0178 - val_loss: -899461.8016 - val_accuracy: 0.0226\n",
            "Epoch 78/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1120425.9565 - accuracy: 0.0178 - val_loss: -930982.7663 - val_accuracy: 0.0226\n",
            "Epoch 79/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1144262.4620 - accuracy: 0.0178 - val_loss: -1024780.8587 - val_accuracy: 0.0226\n",
            "Epoch 80/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1168054.2582 - accuracy: 0.0178 - val_loss: -965745.6359 - val_accuracy: 0.0226\n",
            "Epoch 81/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1196163.4837 - accuracy: 0.0178 - val_loss: -963376.3315 - val_accuracy: 0.0226\n",
            "Epoch 82/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1220376.1929 - accuracy: 0.0178 - val_loss: -945939.6467 - val_accuracy: 0.0226\n",
            "Epoch 83/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1247167.3940 - accuracy: 0.0178 - val_loss: -947266.0027 - val_accuracy: 0.0226\n",
            "Epoch 84/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1271933.8071 - accuracy: 0.0178 - val_loss: -1030673.2391 - val_accuracy: 0.0226\n",
            "Epoch 85/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1297868.9375 - accuracy: 0.0178 - val_loss: -1107750.1522 - val_accuracy: 0.0226\n",
            "Epoch 86/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1325360.5190 - accuracy: 0.0178 - val_loss: -983998.4185 - val_accuracy: 0.0226\n",
            "Epoch 87/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1351330.4592 - accuracy: 0.0178 - val_loss: -1023968.7065 - val_accuracy: 0.0226\n",
            "Epoch 88/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1377066.1821 - accuracy: 0.0178 - val_loss: -1112339.0870 - val_accuracy: 0.0226\n",
            "Epoch 89/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1407744.6060 - accuracy: 0.0178 - val_loss: -1158303.1359 - val_accuracy: 0.0226\n",
            "Epoch 90/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1434301.3560 - accuracy: 0.0178 - val_loss: -1087957.1304 - val_accuracy: 0.0226\n",
            "Epoch 91/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1464586.9592 - accuracy: 0.0178 - val_loss: -1109414.4457 - val_accuracy: 0.0226\n",
            "Epoch 92/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1491308.9375 - accuracy: 0.0178 - val_loss: -1128776.2609 - val_accuracy: 0.0226\n",
            "Epoch 93/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1519587.0190 - accuracy: 0.0178 - val_loss: -1202082.1793 - val_accuracy: 0.0226\n",
            "Epoch 94/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1547288.8832 - accuracy: 0.0178 - val_loss: -1313421.6576 - val_accuracy: 0.0226\n",
            "Epoch 95/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1575799.6250 - accuracy: 0.0178 - val_loss: -1237332.5000 - val_accuracy: 0.0226\n",
            "Epoch 96/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1606002.0027 - accuracy: 0.0178 - val_loss: -1154981.8587 - val_accuracy: 0.0226\n",
            "Epoch 97/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -1634048.9130 - accuracy: 0.0178 - val_loss: -1153154.3641 - val_accuracy: 0.0226\n",
            "Epoch 98/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1665798.5788 - accuracy: 0.0178 - val_loss: -1260270.2337 - val_accuracy: 0.0226\n",
            "Epoch 99/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1692482.5299 - accuracy: 0.0178 - val_loss: -1191621.7826 - val_accuracy: 0.0226\n",
            "Epoch 100/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1723627.8288 - accuracy: 0.0178 - val_loss: -1371760.1957 - val_accuracy: 0.0226\n",
            "Epoch 101/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1750575.5788 - accuracy: 0.0178 - val_loss: -1343768.7065 - val_accuracy: 0.0226\n",
            "Epoch 102/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1783064.3804 - accuracy: 0.0178 - val_loss: -1308511.7446 - val_accuracy: 0.0226\n",
            "Epoch 103/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1812829.5625 - accuracy: 0.0178 - val_loss: -1411251.6196 - val_accuracy: 0.0226\n",
            "Epoch 104/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1845661.3995 - accuracy: 0.0178 - val_loss: -1519358.7500 - val_accuracy: 0.0226\n",
            "Epoch 105/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1874933.7201 - accuracy: 0.0178 - val_loss: -1430765.4348 - val_accuracy: 0.0226\n",
            "Epoch 106/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1905764.0136 - accuracy: 0.0178 - val_loss: -1430291.4674 - val_accuracy: 0.0226\n",
            "Epoch 107/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1939057.4674 - accuracy: 0.0178 - val_loss: -1481444.3043 - val_accuracy: 0.0226\n",
            "Epoch 108/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -1967978.2690 - accuracy: 0.0178 - val_loss: -1465380.8315 - val_accuracy: 0.0226\n",
            "Epoch 109/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2001404.5353 - accuracy: 0.0178 - val_loss: -1525862.2446 - val_accuracy: 0.0226\n",
            "Epoch 110/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2032282.7310 - accuracy: 0.0178 - val_loss: -1511962.5380 - val_accuracy: 0.0226\n",
            "Epoch 111/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2065107.5489 - accuracy: 0.0178 - val_loss: -1669448.6196 - val_accuracy: 0.0226\n",
            "Epoch 112/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2098901.4891 - accuracy: 0.0178 - val_loss: -1630043.9891 - val_accuracy: 0.0226\n",
            "Epoch 113/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2129884.3505 - accuracy: 0.0178 - val_loss: -1795031.5326 - val_accuracy: 0.0226\n",
            "Epoch 114/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2164324.0326 - accuracy: 0.0178 - val_loss: -1706902.1957 - val_accuracy: 0.0226\n",
            "Epoch 115/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2194998.9620 - accuracy: 0.0178 - val_loss: -1763039.1739 - val_accuracy: 0.0226\n",
            "Epoch 116/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2227992.0326 - accuracy: 0.0178 - val_loss: -1823472.4891 - val_accuracy: 0.0226\n",
            "Epoch 117/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2261679.0109 - accuracy: 0.0178 - val_loss: -1647521.2500 - val_accuracy: 0.0226\n",
            "Epoch 118/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2292801.1141 - accuracy: 0.0178 - val_loss: -1700746.4946 - val_accuracy: 0.0226\n",
            "Epoch 119/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2327029.4674 - accuracy: 0.0178 - val_loss: -1720186.4348 - val_accuracy: 0.0226\n",
            "Epoch 120/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2360857.4565 - accuracy: 0.0178 - val_loss: -1891909.7391 - val_accuracy: 0.0226\n",
            "Epoch 121/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2395214.8098 - accuracy: 0.0178 - val_loss: -1982466.8152 - val_accuracy: 0.0226\n",
            "Epoch 122/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2427158.4837 - accuracy: 0.0178 - val_loss: -2208199.8587 - val_accuracy: 0.0226\n",
            "Epoch 123/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2463678.9620 - accuracy: 0.0178 - val_loss: -1916636.0272 - val_accuracy: 0.0226\n",
            "Epoch 124/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2497710.9891 - accuracy: 0.0178 - val_loss: -1836601.9130 - val_accuracy: 0.0226\n",
            "Epoch 125/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2532002.5978 - accuracy: 0.0178 - val_loss: -1943454.9457 - val_accuracy: 0.0226\n",
            "Epoch 126/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -2566357.8098 - accuracy: 0.0178 - val_loss: -1838918.4293 - val_accuracy: 0.0226\n",
            "Epoch 127/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2603233.0707 - accuracy: 0.0178 - val_loss: -2121458.1413 - val_accuracy: 0.0226\n",
            "Epoch 128/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2635959.4348 - accuracy: 0.0178 - val_loss: -1960835.4891 - val_accuracy: 0.0226\n",
            "Epoch 129/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2674652.9293 - accuracy: 0.0178 - val_loss: -2035244.4565 - val_accuracy: 0.0226\n",
            "Epoch 130/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2712143.4402 - accuracy: 0.0178 - val_loss: -2034694.8804 - val_accuracy: 0.0226\n",
            "Epoch 131/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2747586.5598 - accuracy: 0.0178 - val_loss: -1966375.5924 - val_accuracy: 0.0226\n",
            "Epoch 132/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2784202.4511 - accuracy: 0.0178 - val_loss: -2085474.2391 - val_accuracy: 0.0226\n",
            "Epoch 133/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2820618.0924 - accuracy: 0.0178 - val_loss: -2024635.3152 - val_accuracy: 0.0226\n",
            "Epoch 134/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2852399.9348 - accuracy: 0.0178 - val_loss: -2062982.5326 - val_accuracy: 0.0226\n",
            "Epoch 135/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2895226.4239 - accuracy: 0.0178 - val_loss: -2361908.4348 - val_accuracy: 0.0226\n",
            "Epoch 136/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2932025.4728 - accuracy: 0.0178 - val_loss: -2276081.6304 - val_accuracy: 0.0226\n",
            "Epoch 137/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -2968460.4076 - accuracy: 0.0178 - val_loss: -2286380.8152 - val_accuracy: 0.0226\n",
            "Epoch 138/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3004990.4674 - accuracy: 0.0178 - val_loss: -2415748.1522 - val_accuracy: 0.0226\n",
            "Epoch 139/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3039783.4130 - accuracy: 0.0178 - val_loss: -2410771.8804 - val_accuracy: 0.0226\n",
            "Epoch 140/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3079105.1304 - accuracy: 0.0178 - val_loss: -2521914.2826 - val_accuracy: 0.0226\n",
            "Epoch 141/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3120485.9402 - accuracy: 0.0178 - val_loss: -2359320.5652 - val_accuracy: 0.0226\n",
            "Epoch 142/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3157018.9293 - accuracy: 0.0178 - val_loss: -2341033.1630 - val_accuracy: 0.0226\n",
            "Epoch 143/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3192147.7120 - accuracy: 0.0178 - val_loss: -2455572.3043 - val_accuracy: 0.0226\n",
            "Epoch 144/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3231168.9293 - accuracy: 0.0178 - val_loss: -2471751.6413 - val_accuracy: 0.0226\n",
            "Epoch 145/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3267885.7337 - accuracy: 0.0178 - val_loss: -2411302.8804 - val_accuracy: 0.0226\n",
            "Epoch 146/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3315053.8913 - accuracy: 0.0178 - val_loss: -2579869.7935 - val_accuracy: 0.0226\n",
            "Epoch 147/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3346572.0707 - accuracy: 0.0178 - val_loss: -2488326.4891 - val_accuracy: 0.0226\n",
            "Epoch 148/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3391378.0652 - accuracy: 0.0178 - val_loss: -2629339.0543 - val_accuracy: 0.0226\n",
            "Epoch 149/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3427141.3641 - accuracy: 0.0178 - val_loss: -2572992.2174 - val_accuracy: 0.0226\n",
            "Epoch 150/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3465898.4565 - accuracy: 0.0178 - val_loss: -2542854.2391 - val_accuracy: 0.0226\n",
            "Epoch 151/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3506822.4293 - accuracy: 0.0178 - val_loss: -2447571.3370 - val_accuracy: 0.0226\n",
            "Epoch 152/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3547024.7228 - accuracy: 0.0178 - val_loss: -2424894.7609 - val_accuracy: 0.0226\n",
            "Epoch 153/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3591845.1793 - accuracy: 0.0178 - val_loss: -2623089.4348 - val_accuracy: 0.0226\n",
            "Epoch 154/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -3632301.5163 - accuracy: 0.0178 - val_loss: -2640098.6304 - val_accuracy: 0.0226\n",
            "Epoch 155/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3674010.2826 - accuracy: 0.0178 - val_loss: -2905694.5435 - val_accuracy: 0.0226\n",
            "Epoch 156/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3710905.7174 - accuracy: 0.0178 - val_loss: -2854814.7283 - val_accuracy: 0.0226\n",
            "Epoch 157/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3751853.3478 - accuracy: 0.0178 - val_loss: -2914245.3587 - val_accuracy: 0.0226\n",
            "Epoch 158/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3797120.1359 - accuracy: 0.0178 - val_loss: -2995359.6087 - val_accuracy: 0.0226\n",
            "Epoch 159/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3837757.2880 - accuracy: 0.0178 - val_loss: -2812835.2609 - val_accuracy: 0.0226\n",
            "Epoch 160/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3875417.5217 - accuracy: 0.0178 - val_loss: -2939666.4130 - val_accuracy: 0.0226\n",
            "Epoch 161/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3921415.9783 - accuracy: 0.0178 - val_loss: -3011021.0435 - val_accuracy: 0.0226\n",
            "Epoch 162/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -3966596.8859 - accuracy: 0.0178 - val_loss: -3058085.0217 - val_accuracy: 0.0226\n",
            "Epoch 163/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4007395.3152 - accuracy: 0.0178 - val_loss: -3028348.2391 - val_accuracy: 0.0226\n",
            "Epoch 164/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4050595.9348 - accuracy: 0.0178 - val_loss: -3212908.6304 - val_accuracy: 0.0226\n",
            "Epoch 165/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4089454.7609 - accuracy: 0.0178 - val_loss: -3140909.1304 - val_accuracy: 0.0226\n",
            "Epoch 166/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4129802.6957 - accuracy: 0.0178 - val_loss: -3372378.6630 - val_accuracy: 0.0226\n",
            "Epoch 167/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4178794.8859 - accuracy: 0.0178 - val_loss: -3089463.5000 - val_accuracy: 0.0226\n",
            "Epoch 168/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4218022.6576 - accuracy: 0.0178 - val_loss: -3557387.6630 - val_accuracy: 0.0226\n",
            "Epoch 169/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4261708.7120 - accuracy: 0.0178 - val_loss: -3325812.5217 - val_accuracy: 0.0226\n",
            "Epoch 170/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4310125.2880 - accuracy: 0.0178 - val_loss: -3325540.8261 - val_accuracy: 0.0226\n",
            "Epoch 171/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4352410.1902 - accuracy: 0.0178 - val_loss: -3374783.0217 - val_accuracy: 0.0226\n",
            "Epoch 172/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4397795.0761 - accuracy: 0.0178 - val_loss: -3302938.5435 - val_accuracy: 0.0226\n",
            "Epoch 173/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4440157.7772 - accuracy: 0.0178 - val_loss: -3401529.8913 - val_accuracy: 0.0226\n",
            "Epoch 174/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4484888.2717 - accuracy: 0.0178 - val_loss: -3475958.4674 - val_accuracy: 0.0226\n",
            "Epoch 175/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4531527.8913 - accuracy: 0.0178 - val_loss: -3578187.7717 - val_accuracy: 0.0226\n",
            "Epoch 176/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4572224.7772 - accuracy: 0.0178 - val_loss: -3590604.8478 - val_accuracy: 0.0226\n",
            "Epoch 177/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4615385.5761 - accuracy: 0.0178 - val_loss: -3576660.7283 - val_accuracy: 0.0226\n",
            "Epoch 178/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4662557.0543 - accuracy: 0.0178 - val_loss: -3409427.4022 - val_accuracy: 0.0226\n",
            "Epoch 179/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4708190.6957 - accuracy: 0.0178 - val_loss: -3572029.6304 - val_accuracy: 0.0226\n",
            "Epoch 180/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4754786.4674 - accuracy: 0.0178 - val_loss: -3432548.0870 - val_accuracy: 0.0226\n",
            "Epoch 181/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4798930.5761 - accuracy: 0.0178 - val_loss: -3588734.4130 - val_accuracy: 0.0226\n",
            "Epoch 182/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4845960.2935 - accuracy: 0.0178 - val_loss: -3630372.1739 - val_accuracy: 0.0226\n",
            "Epoch 183/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -4892275.8696 - accuracy: 0.0178 - val_loss: -3700860.4239 - val_accuracy: 0.0226\n",
            "Epoch 184/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4936921.5978 - accuracy: 0.0178 - val_loss: -3821216.3152 - val_accuracy: 0.0226\n",
            "Epoch 185/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -4991379.3478 - accuracy: 0.0178 - val_loss: -3941078.6196 - val_accuracy: 0.0226\n",
            "Epoch 186/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5026080.4239 - accuracy: 0.0178 - val_loss: -3905779.8913 - val_accuracy: 0.0226\n",
            "Epoch 187/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5070106.5217 - accuracy: 0.0178 - val_loss: -4075634.3043 - val_accuracy: 0.0226\n",
            "Epoch 188/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5128075.7935 - accuracy: 0.0178 - val_loss: -4251382.7391 - val_accuracy: 0.0226\n",
            "Epoch 189/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5176706.0761 - accuracy: 0.0178 - val_loss: -4003588.6848 - val_accuracy: 0.0226\n",
            "Epoch 190/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5220005.6522 - accuracy: 0.0178 - val_loss: -3763899.9457 - val_accuracy: 0.0226\n",
            "Epoch 191/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5263043.8043 - accuracy: 0.0178 - val_loss: -4133206.7174 - val_accuracy: 0.0226\n",
            "Epoch 192/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5314122.9674 - accuracy: 0.0178 - val_loss: -3755824.0326 - val_accuracy: 0.0226\n",
            "Epoch 193/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5363627.1848 - accuracy: 0.0178 - val_loss: -4001813.7174 - val_accuracy: 0.0226\n",
            "Epoch 194/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5412982.0000 - accuracy: 0.0178 - val_loss: -4060752.5435 - val_accuracy: 0.0226\n",
            "Epoch 195/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5461869.7717 - accuracy: 0.0178 - val_loss: -4181215.3261 - val_accuracy: 0.0226\n",
            "Epoch 196/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5509986.2609 - accuracy: 0.0178 - val_loss: -4123599.9239 - val_accuracy: 0.0226\n",
            "Epoch 197/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5565033.5109 - accuracy: 0.0178 - val_loss: -4433896.5652 - val_accuracy: 0.0226\n",
            "Epoch 198/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5601891.6848 - accuracy: 0.0178 - val_loss: -4132939.4891 - val_accuracy: 0.0226\n",
            "Epoch 199/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5656125.4130 - accuracy: 0.0178 - val_loss: -4571804.4565 - val_accuracy: 0.0226\n",
            "Epoch 200/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5701962.2500 - accuracy: 0.0178 - val_loss: -4465095.1304 - val_accuracy: 0.0226\n",
            "Epoch 201/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5752182.7826 - accuracy: 0.0178 - val_loss: -4071318.3913 - val_accuracy: 0.0226\n",
            "Epoch 202/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5804935.3696 - accuracy: 0.0178 - val_loss: -4331930.9565 - val_accuracy: 0.0226\n",
            "Epoch 203/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5849367.6739 - accuracy: 0.0178 - val_loss: -4986862.1957 - val_accuracy: 0.0226\n",
            "Epoch 204/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5905863.7935 - accuracy: 0.0178 - val_loss: -4896102.6522 - val_accuracy: 0.0226\n",
            "Epoch 205/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -5947080.5543 - accuracy: 0.0178 - val_loss: -4360869.0870 - val_accuracy: 0.0226\n",
            "Epoch 206/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6008431.9565 - accuracy: 0.0178 - val_loss: -4395018.0000 - val_accuracy: 0.0226\n",
            "Epoch 207/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6058641.8152 - accuracy: 0.0178 - val_loss: -4473809.1087 - val_accuracy: 0.0226\n",
            "Epoch 208/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6113803.7717 - accuracy: 0.0178 - val_loss: -4615635.3478 - val_accuracy: 0.0226\n",
            "Epoch 209/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6161347.3696 - accuracy: 0.0178 - val_loss: -4439975.5000 - val_accuracy: 0.0226\n",
            "Epoch 210/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6217563.3370 - accuracy: 0.0178 - val_loss: -4582734.1739 - val_accuracy: 0.0226\n",
            "Epoch 211/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6268196.7935 - accuracy: 0.0178 - val_loss: -4558463.4565 - val_accuracy: 0.0226\n",
            "Epoch 212/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6323252.7391 - accuracy: 0.0178 - val_loss: -4510470.7609 - val_accuracy: 0.0226\n",
            "Epoch 213/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6377318.0435 - accuracy: 0.0178 - val_loss: -4695277.0000 - val_accuracy: 0.0226\n",
            "Epoch 214/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6418239.3696 - accuracy: 0.0178 - val_loss: -5204791.8696 - val_accuracy: 0.0226\n",
            "Epoch 215/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6473134.2174 - accuracy: 0.0178 - val_loss: -5126999.4783 - val_accuracy: 0.0226\n",
            "Epoch 216/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6531103.2500 - accuracy: 0.0178 - val_loss: -5312717.8261 - val_accuracy: 0.0226\n",
            "Epoch 217/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6576709.1739 - accuracy: 0.0178 - val_loss: -4689520.5870 - val_accuracy: 0.0226\n",
            "Epoch 218/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6629426.2826 - accuracy: 0.0178 - val_loss: -5133813.2609 - val_accuracy: 0.0226\n",
            "Epoch 219/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6678463.3696 - accuracy: 0.0178 - val_loss: -4989984.2826 - val_accuracy: 0.0226\n",
            "Epoch 220/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6742460.4239 - accuracy: 0.0178 - val_loss: -5165895.7826 - val_accuracy: 0.0226\n",
            "Epoch 221/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6795159.3152 - accuracy: 0.0178 - val_loss: -5024687.4783 - val_accuracy: 0.0226\n",
            "Epoch 222/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6839528.8587 - accuracy: 0.0178 - val_loss: -4949616.0435 - val_accuracy: 0.0226\n",
            "Epoch 223/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6906482.2717 - accuracy: 0.0178 - val_loss: -5320348.2174 - val_accuracy: 0.0226\n",
            "Epoch 224/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -6949726.3152 - accuracy: 0.0178 - val_loss: -5077799.3478 - val_accuracy: 0.0226\n",
            "Epoch 225/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7004756.6087 - accuracy: 0.0178 - val_loss: -5402936.1522 - val_accuracy: 0.0226\n",
            "Epoch 226/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7060857.3913 - accuracy: 0.0178 - val_loss: -5329808.1739 - val_accuracy: 0.0226\n",
            "Epoch 227/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7115950.5543 - accuracy: 0.0178 - val_loss: -5466033.1739 - val_accuracy: 0.0226\n",
            "Epoch 228/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7166558.8587 - accuracy: 0.0178 - val_loss: -5397243.0435 - val_accuracy: 0.0226\n",
            "Epoch 229/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7230448.4130 - accuracy: 0.0178 - val_loss: -5744391.4783 - val_accuracy: 0.0226\n",
            "Epoch 230/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7284492.4130 - accuracy: 0.0178 - val_loss: -5764934.4783 - val_accuracy: 0.0226\n",
            "Epoch 231/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7341737.1196 - accuracy: 0.0178 - val_loss: -5585467.5000 - val_accuracy: 0.0226\n",
            "Epoch 232/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7389616.0217 - accuracy: 0.0178 - val_loss: -5495067.3478 - val_accuracy: 0.0226\n",
            "Epoch 233/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7449035.3913 - accuracy: 0.0178 - val_loss: -5445954.0870 - val_accuracy: 0.0226\n",
            "Epoch 234/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7512408.5000 - accuracy: 0.0178 - val_loss: -5817490.7826 - val_accuracy: 0.0226\n",
            "Epoch 235/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7564833.5978 - accuracy: 0.0178 - val_loss: -5553175.4348 - val_accuracy: 0.0226\n",
            "Epoch 236/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7624128.6957 - accuracy: 0.0178 - val_loss: -6032651.8261 - val_accuracy: 0.0226\n",
            "Epoch 237/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7680998.9239 - accuracy: 0.0178 - val_loss: -5678468.8261 - val_accuracy: 0.0226\n",
            "Epoch 238/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7734338.7609 - accuracy: 0.0178 - val_loss: -6062468.3478 - val_accuracy: 0.0226\n",
            "Epoch 239/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7797359.6196 - accuracy: 0.0178 - val_loss: -5984754.2609 - val_accuracy: 0.0226\n",
            "Epoch 240/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -7842848.3587 - accuracy: 0.0178 - val_loss: -6272963.2391 - val_accuracy: 0.0226\n",
            "Epoch 241/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7913305.6304 - accuracy: 0.0178 - val_loss: -6065524.3913 - val_accuracy: 0.0226\n",
            "Epoch 242/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -7955974.9022 - accuracy: 0.0178 - val_loss: -6340605.7391 - val_accuracy: 0.0226\n",
            "Epoch 243/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8020147.1304 - accuracy: 0.0178 - val_loss: -6081688.5217 - val_accuracy: 0.0226\n",
            "Epoch 244/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8086851.8587 - accuracy: 0.0178 - val_loss: -6078302.1739 - val_accuracy: 0.0226\n",
            "Epoch 245/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8152339.9674 - accuracy: 0.0178 - val_loss: -6548204.2609 - val_accuracy: 0.0226\n",
            "Epoch 246/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8195114.4565 - accuracy: 0.0178 - val_loss: -6451797.6087 - val_accuracy: 0.0226\n",
            "Epoch 247/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8251269.3370 - accuracy: 0.0178 - val_loss: -6276896.0000 - val_accuracy: 0.0226\n",
            "Epoch 248/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8319736.5217 - accuracy: 0.0178 - val_loss: -6352506.7391 - val_accuracy: 0.0226\n",
            "Epoch 249/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8375714.1413 - accuracy: 0.0178 - val_loss: -6265281.0870 - val_accuracy: 0.0226\n",
            "Epoch 250/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8431241.5978 - accuracy: 0.0178 - val_loss: -6280972.8261 - val_accuracy: 0.0226\n",
            "Epoch 251/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8501526.0652 - accuracy: 0.0178 - val_loss: -6574571.0217 - val_accuracy: 0.0226\n",
            "Epoch 252/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8550769.2283 - accuracy: 0.0178 - val_loss: -6758799.5217 - val_accuracy: 0.0226\n",
            "Epoch 253/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8603480.9674 - accuracy: 0.0178 - val_loss: -6821793.4348 - val_accuracy: 0.0226\n",
            "Epoch 254/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8663708.6413 - accuracy: 0.0178 - val_loss: -6822489.6957 - val_accuracy: 0.0226\n",
            "Epoch 255/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8733577.7717 - accuracy: 0.0178 - val_loss: -6573981.6304 - val_accuracy: 0.0226\n",
            "Epoch 256/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8802216.8043 - accuracy: 0.0178 - val_loss: -6836258.1522 - val_accuracy: 0.0226\n",
            "Epoch 257/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8854586.7609 - accuracy: 0.0178 - val_loss: -6701467.4348 - val_accuracy: 0.0226\n",
            "Epoch 258/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8906833.3043 - accuracy: 0.0178 - val_loss: -6827906.4783 - val_accuracy: 0.0226\n",
            "Epoch 259/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -8965140.2609 - accuracy: 0.0178 - val_loss: -6736746.3913 - val_accuracy: 0.0226\n",
            "Epoch 260/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9024107.1413 - accuracy: 0.0178 - val_loss: -7139102.7174 - val_accuracy: 0.0226\n",
            "Epoch 261/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9093793.3261 - accuracy: 0.0178 - val_loss: -6790504.2391 - val_accuracy: 0.0226\n",
            "Epoch 262/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9144105.2174 - accuracy: 0.0178 - val_loss: -6862385.3261 - val_accuracy: 0.0226\n",
            "Epoch 263/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9220954.8913 - accuracy: 0.0178 - val_loss: -6942687.7391 - val_accuracy: 0.0226\n",
            "Epoch 264/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9280377.1739 - accuracy: 0.0178 - val_loss: -7150034.2174 - val_accuracy: 0.0226\n",
            "Epoch 265/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9337342.7391 - accuracy: 0.0178 - val_loss: -6801675.8696 - val_accuracy: 0.0226\n",
            "Epoch 266/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9403803.1957 - accuracy: 0.0178 - val_loss: -7368654.0435 - val_accuracy: 0.0226\n",
            "Epoch 267/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9463433.3043 - accuracy: 0.0178 - val_loss: -7416345.1087 - val_accuracy: 0.0226\n",
            "Epoch 268/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -9533741.8043 - accuracy: 0.0178 - val_loss: -7270129.8696 - val_accuracy: 0.0226\n",
            "Epoch 269/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9584103.6957 - accuracy: 0.0178 - val_loss: -7304000.1304 - val_accuracy: 0.0226\n",
            "Epoch 270/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9653500.1087 - accuracy: 0.0178 - val_loss: -7677125.0435 - val_accuracy: 0.0226\n",
            "Epoch 271/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9724895.9130 - accuracy: 0.0178 - val_loss: -7578651.1087 - val_accuracy: 0.0226\n",
            "Epoch 272/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9776583.5217 - accuracy: 0.0178 - val_loss: -7527976.1739 - val_accuracy: 0.0226\n",
            "Epoch 273/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9848198.8478 - accuracy: 0.0178 - val_loss: -7501653.1304 - val_accuracy: 0.0226\n",
            "Epoch 274/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9902064.5870 - accuracy: 0.0178 - val_loss: -7468498.6957 - val_accuracy: 0.0226\n",
            "Epoch 275/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -9959878.7826 - accuracy: 0.0178 - val_loss: -9371646.3478 - val_accuracy: 0.0226\n",
            "Epoch 276/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10027213.2609 - accuracy: 0.0178 - val_loss: -8134645.6522 - val_accuracy: 0.0226\n",
            "Epoch 277/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10098068.6522 - accuracy: 0.0178 - val_loss: -7423869.7391 - val_accuracy: 0.0226\n",
            "Epoch 278/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10152624.9783 - accuracy: 0.0178 - val_loss: -7746798.0217 - val_accuracy: 0.0226\n",
            "Epoch 279/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10206112.5435 - accuracy: 0.0178 - val_loss: -8195425.3913 - val_accuracy: 0.0226\n",
            "Epoch 280/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10285453.7826 - accuracy: 0.0178 - val_loss: -7294253.1304 - val_accuracy: 0.0226\n",
            "Epoch 281/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10326866.8478 - accuracy: 0.0178 - val_loss: -8664054.9130 - val_accuracy: 0.0226\n",
            "Epoch 282/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10407379.0435 - accuracy: 0.0178 - val_loss: -8094653.1957 - val_accuracy: 0.0226\n",
            "Epoch 283/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10486131.9130 - accuracy: 0.0178 - val_loss: -7570892.6739 - val_accuracy: 0.0226\n",
            "Epoch 284/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10551766.0000 - accuracy: 0.0178 - val_loss: -7346732.6304 - val_accuracy: 0.0226\n",
            "Epoch 285/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10626559.6957 - accuracy: 0.0178 - val_loss: -7590183.6304 - val_accuracy: 0.0226\n",
            "Epoch 286/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10683993.1087 - accuracy: 0.0178 - val_loss: -7520589.5652 - val_accuracy: 0.0226\n",
            "Epoch 287/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10742292.9783 - accuracy: 0.0178 - val_loss: -7961411.1522 - val_accuracy: 0.0226\n",
            "Epoch 288/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10813783.0870 - accuracy: 0.0178 - val_loss: -7837831.7391 - val_accuracy: 0.0226\n",
            "Epoch 289/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10888008.4348 - accuracy: 0.0178 - val_loss: -7691556.4783 - val_accuracy: 0.0226\n",
            "Epoch 290/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -10942468.0435 - accuracy: 0.0178 - val_loss: -7660655.4348 - val_accuracy: 0.0226\n",
            "Epoch 291/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -11021267.3696 - accuracy: 0.0178 - val_loss: -7736239.8696 - val_accuracy: 0.0226\n",
            "Epoch 292/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -11087604.7391 - accuracy: 0.0178 - val_loss: -7823109.4565 - val_accuracy: 0.0226\n",
            "Epoch 293/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -11139855.8478 - accuracy: 0.0178 - val_loss: -7971326.0652 - val_accuracy: 0.0226\n",
            "Epoch 294/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -11221795.9783 - accuracy: 0.0178 - val_loss: -8320334.6087 - val_accuracy: 0.0226\n",
            "Epoch 295/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -11283535.8913 - accuracy: 0.0178 - val_loss: -8349729.5217 - val_accuracy: 0.0226\n",
            "Epoch 296/300\n",
            "92/92 [==============================] - 3s 36ms/step - loss: -11362908.1522 - accuracy: 0.0178 - val_loss: -8257910.9130 - val_accuracy: 0.0226\n",
            "Epoch 297/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -11434477.6522 - accuracy: 0.0178 - val_loss: -8488988.4783 - val_accuracy: 0.0226\n",
            "Epoch 298/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -11495640.7391 - accuracy: 0.0178 - val_loss: -8312651.1739 - val_accuracy: 0.0226\n",
            "Epoch 299/300\n",
            "92/92 [==============================] - 3s 34ms/step - loss: -11549722.0870 - accuracy: 0.0178 - val_loss: -8471416.2609 - val_accuracy: 0.0226\n",
            "Epoch 300/300\n",
            "92/92 [==============================] - 3s 35ms/step - loss: -11617106.3913 - accuracy: 0.0178 - val_loss: -8541916.0435 - val_accuracy: 0.0226\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_images, train_masks, batch_size=2, epochs=300, verbose=1, validation_data=(test_images, test_masks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WLnv7acaYA-R",
        "outputId": "e0877022-76ea-4af1-98e8-6aae80f06b57"
      },
      "outputs": [],
      "source": [
        "#accuracy = model.evaluate(x_val, y_val)\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('tight_LinkNet_Loss.jpg',dpi=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jQT2tgHQdNFM",
        "outputId": "ac78dd83-4917-4c4f-8beb-465047a58ba8"
      },
      "outputs": [],
      "source": [
        "#accuracy = model.evaluate(x_val, y_val)\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('tight_LinkNet_Accuracy.jpg',dpi=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvaDNhmRbIJw"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Dataset/INbreast/checkpoint/breast_full/INBREAST_tight_LinkNet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRiuCz4BbZh_"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/Dataset/INbreast/checkpoint/breast_full/INBREAST_tight_LinkNet.h5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsGuvMWbiaTm"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0M81f5DigZO",
        "outputId": "d62bea48-9b75-4089-dc19-b30551e088dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23, 256, 256, 3)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S9z8xQnijjC"
      },
      "outputs": [],
      "source": [
        "img_dir = os.listdir(\"/content/drive/MyDrive/Dataset/INbreast/dataset/breast_tight/test/b/\")\n",
        "img_names = []\n",
        "for index,img_id in enumerate(img_dir):\n",
        "    img_names.append(img_id)\n",
        "\n",
        "i = 0\n",
        "for img_msk in prediction:\n",
        "    plt.imsave(f\"/content/sample_data/Result/{img_names[i]}\",img_msk,dpi=300)\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_w2bapEjiW1",
        "outputId": "5c035fa3-767c-4267-c110-f4f586ee5273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/sample_data/Result/ (stored 0%)\n",
            "  adding: content/sample_data/Result/20587758.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/20587994.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/2_51049107.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/20587612.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/2_20586908.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/20587664.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/2_22427840.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/20587902.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/2_22580341.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/20586934.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/2_22579730.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/2_22580367.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/20586908.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/2_20586960.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/20587810.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/20586986.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/20588216.jpeg (deflated 59%)\n",
            "  adding: content/sample_data/Result/20588046.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/2_24055464.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/20587928.jpeg (deflated 61%)\n",
            "  adding: content/sample_data/Result/20586960.jpeg (deflated 58%)\n",
            "  adding: content/sample_data/Result/2_22613770.jpeg (deflated 60%)\n",
            "  adding: content/sample_data/Result/20588190.jpeg (deflated 58%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/tight_Link.zip /content/sample_data/Result"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "INBreast_Segmentation_UNet.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
